# 评价

# 第一章

1.  正确答案是:4，5。
2.  对于信息技术来说，码头工人集装箱就像运输行业的集装箱一样。它定义了如何包装商品的标准。在这种情况下，商品是开发人员编写的应用。供应商(在这种情况下是开发人员)负责将货物包装到容器中，并确保一切都符合预期。一旦货物被包装成集装箱，就可以装运了。由于它是一个标准集装箱，托运人可以标准化他们的运输工具，如卡车、火车或轮船。托运人并不真正关心集装箱里有什么。此外，从一种运输方式到另一种运输方式(例如，火车到轮船)的装卸过程可以高度标准化。这大大提高了运输效率。与此类似的是一名 IT 运营工程师，他可以将开发人员构建的软件容器运送到生产系统，并以高度标准化的方式在那里运行，而无需担心容器中有什么。它会起作用的。
3.  容器成为游戏改变者的一些原因是:
    *   容器是独立的，因此如果它们在一个系统上运行，它们可以在容器可以运行的任何地方运行。
    *   容器在内部、云中以及混合环境中运行。这对于当今典型的企业来说非常重要，因为它允许从内部部署到云的平稳过渡。
    *   容器映像是由最了解的人——开发人员——构建或打包的。
    *   容器映像是不可变的，这对于良好的发布管理很重要。
    *   容器是基于封装(使用 Linux 命名空间和 cgroups)、秘密、内容信任和映像漏洞扫描的安全软件供应链的推动者。

4.  容器可以在任何地方运行，因为:
    *   容器是独立的黑盒。它们不仅封装了一个应用，还封装了它的所有依赖项，例如库和框架、配置数据、证书等等。
    *   集装箱基于广泛接受的标准，如 OCI。
    *   TODO:添加更多原因。
5.  假的！容器对于现代应用以及容器化传统应用都是有用的。企业做后者的好处是巨大的。据报道，传统应用的维护成本节约了 50%或更多。此类遗留应用的新版本之间的时间间隔最多可缩短 90%。这些数字已经被真实的企业客户公开报道。
6.  50%或更多。
7.  容器基于 Linux 命名空间(网络、进程、用户等)和 cgroups(控制组)。

# 第二章

1.  `docker-machine`可以用来做以下事情:
    *   创建一个在不同环境中配置为 Docker 主机的虚拟机，例如 VirtualBox
    *   SSH 进入 Docker 主机
    *   为远程 Docker 主机的访问配置本地 Docker 命令行界面
    *   列出给定环境中的所有主机
    *   删除或销毁现有主机
2.  没错。Windows docker 在 Hyper-V 中创建了一个 Linux 虚拟机，然后在其上运行 Linux 容器。
3.  容器被最佳地用在 CI/CD 中，这完全是关于自动化。从构建容器映像、运送映像到最终从该映像运行容器的每一步，都是为了最大限度地提高工作效率而编写的理想脚本。有了它，就可以实现一个可重复和可审计的过程。
4.  Ubuntu 17.4 或更高版本、CentOS 7.x、Alpine 3.x、Debian、Suse Linux、RedHat Linux 等等。
5.  Windows 10 专业版或企业版，Windows Server 2016。

# 第三章

1.  容器的状态如下

2.  以下命令有助于我们了解主机上当前运行的是什么:

```
$ docker container ls
```

3.  以下命令用于列出所有容器的标识:

```
$ docker container ls -q
```

# 第四章

以下是这些问题的可能答案:

1.  Dockerfile：

```
FROM ubuntu:17.04
RUN apt-get update
RUN apt-get install -y ping
ENTRYPOINT ping
CMD 127.0.0.1
```

2.  要获得此结果，您可以执行以下步骤:

```
$ docker container run -it --name sample \
 alpine:latest /bin/sh
/ # apk update && \
 apk add -y curl && \
 rm -rf /var/cache/apk/*
/ # exit
$ docker container commit sample my-alpine:1.0
$ docker container rm sample
```

3.  作为示例，这里是 C 中的`Hello World`:
    1.  创建一个包含以下内容的文件`hello.c`:

```
#include <stdio.h>
int main()
{
   printf("Hello, World!");
   return 0;
}
```

```
FROM alpine:3.5 AS build
RUN apk update && \
    apk add --update alpine-sdk
RUN mkdir /app
WORKDIR /app
COPY hello.c /app
RUN mkdir bin
RUN gcc -Wall hello.c -o bin/hello 

FROM alpine:3.5
COPY --from=build /app/bin/hello /app/hello
CMD /app/hello
```

4.  Docker 映像的一些特征是:
    *   它是不可改变的
    *   它由不可变的层组成
    *   每一层仅包含相对于较低层而言已经改变的部分(增量)
    *   映像是文件和文件夹的(大)目标球
    *   映像是容器的模板
5.  选项 3 是正确的。首先，我们需要确保我们已经登录，然后我们标记映像，最后推送它。因为这是一个映像，我们使用的是`docker image ...`而不是`docker container ...`(如数字 4)。

# 第五章

使用卷的最简单方法是使用 Docker 工具箱，就像直接使用 Mac 的 Docker 或 Windows 的 Docker 一样，然后将卷存储在 Mac/Win 的 Docker 透明使用的(有些隐藏的)Linux 虚拟机中。

因此，我们建议如下:

```
$ docker-machine create --driver virtualbox volume-test
$ docker-machine ssh volume-test
```

现在您已经进入了名为`volume-test`的 Linux 虚拟机，您可以执行以下练习:

1.  要创建名为`volume`的，运行以下命令:

```
 $ docker volume create my-products
```

2.  执行以下命令:

```
$ docker container run -it --rm \
 -v my-products:/data:ro \
 alpine /bin/sh
```

3.  例如，要获取卷在主机上的路径，请使用以下命令:

```
$ docker volume inspect my-products | grep Mountpoint
```

(如果使用 docker-machine 和 VirtualBox)会导致:

```
"Mountpoint": "/mnt/sda1/var/lib/docker/volumes/my-products/_data"
```

现在执行以下命令:

```
$ sudo su
$ cd /mnt/sda1/var/lib/docker/volumes/my-products/_data
$ echo "Hello world" > sample.txt
$ exit
```

4.  执行以下命令:

```
$ docker run -it --rm -v my-products:/data:ro alpine /bin/sh
# / cd /data
# / cat sample.txt
```

在另一个终端中执行:

```
 $ docker run -it --rm -v my-products:/app-data alpine /bin/sh
 # / cd /app-data
 # / echo "Hello other container" > hello.txt
 # / exit
```

5.  执行如下命令:

```
$ docker container run -it --rm \
 -v $HOME/my-project:/app/data \
 alpine /bin/sh
```

6.  退出两个容器，然后回到主机上，执行以下命令:

```
$ docker volume prune
```

7.  运行以下命令:

```
$ docker system info | grep Version
```

应该会输出类似这样的内容:

```
Server Version: 17.09.1-ce
Kernel Version: 4.4.104-boot2docker
```

如果您一直在使用`docker-machine`在 VirtualBox 中创建和使用 Linux 虚拟机，请不要忘记在完成后进行清理:

```
$ docker-machine rm volume-test
```

# 第六章

1.  在一个由许多部分组成的系统中，至少一个部分的故障只是时间问题。为了避免出现这种情况时的任何停机时间，我们运行每个组件的多个实例。如果其中一个实例失败，还有其他实例可以满足请求。
2.  在分布式应用架构中，我们有许多活动部分。如果服务 A 需要访问服务 B 的实例，那么它不知道在哪里可以找到这样的实例。实例可以位于集群的任何随机节点上，它们甚至可以根据编排引擎的需要来来去去，因此我们不通过目标实例的 IP 地址和端口来识别目标实例，而是通过其名称和端口来识别。DNS 服务知道如何将服务名称解析为 IP 地址，因为它拥有集群中运行的所有服务实例的所有信息。

3.  断路器是一种机制，有助于避免由单个故障服务触发的分布式应用中的级联故障。断路器观察从一个服务到另一个服务的请求，并测量随时间推移的延迟以及请求失败或超时的次数。如果某个目标实例导致了太多的失败，那么对它的调用就会被拦截，并且错误代码会返回给调用者，如果可能的话，会立即给目标时间进行恢复，而调用者会立即知道它应该降级自己的服务，或者尝试使用目标服务的另一个实例。
4.  单块是由一个高度耦合的代码库组成的应用。如果对代码进行了更改，无论更改多小，都必须编译、打包和重新部署整个应用。由于整体只有很少的活动部件，因此在生产中很容易部署和监控。单片很难维护和扩展。分布式应用由许多松散耦合的服务组成。每项服务都源自其独立的源代码库。单个服务可以并且经常具有独立的生命周期。它们可以独立开发和修改。分布式应用更难管理和监控。
5.  当一个服务的当前运行版本(称为蓝色)被同一个服务的新版本(称为绿色)替换时，就会出现蓝绿色部署。更换过程没有任何停机时间，因为当蓝色版本仍在运行时，系统上安装了绿色版本的服务，一旦准备就绪，就需要对路由器的配置进行简单的更改，将流量引导至服务，这样流量就全部导向绿色而不是蓝色。

# 第七章

1.  三个核心元素是沙箱、端点和网络
2.  执行以下命令:

```
$ docker network create --driver bridge frontend
```

3.  运行以下命令:

```
$ docker container run -d --name n1 \
 --network frontend -p 8080:80 nginx:alpine
$ docker container run -d --name n2 \
 --network frontend -p 8081:80 nginx:alpine
```

测试两个 Nginx 实例是否都已启动并运行:

```
$ curl -4 localhost:8080
$ curl -4 localhost:8081
```

在这两种情况下，您都应该看到 Nginx 的欢迎页面。

4.  要获取所有连接的容器的 IP，请运行:

```
$ docker network inspect frontend | grep IPv4Address
```

您应该会看到类似以下内容的内容:

```
"IPv4Address": "172.18.0.2/16",
"IPv4Address": "172.18.0.3/16",
```

要获取网络使用的子网，请使用以下命令(例如):

```
$ docker network inspect frontend | grep subnet
```

您应该会收到如下内容(从前面的示例中获得):

```
"Subnet": "172.18.0.0/16",
```

5.  `host`网络允许我们在主机的网络命名空间中运行一个容器。
6.  仅将此网络用于调试目的或构建系统级工具。切勿将`host`网络用于运行生产的应用容器！
7.  `none`网络基本上是说容器不依附于任何网络。它应该用于不需要与其他容器通信并且不需要从外部访问的容器。
8.  `none`网络例如可以用于在容器中运行的批处理，该容器只需要访问本地资源，例如可以通过主机安装的卷访问的文件。

# 第八章

1.  以下代码可用于在守护模式下运行应用。

```
$ docker-compose up -d
```

2.  执行以下命令显示正在运行的服务的详细信息。

```
$ docker-compose ps
```

这将产生以下输出:

```
Name             Command              State  Ports
-------------------------------------------------------------------
mycontent_nginx_1 nginx -g daemon off; Up     0.0.0.0:3000->80/tcp
```

3.  以下命令可用于扩展 web 服务:

```
$ docker-compose up --scale web=3
```

# 第九章

以下是本章问题的示例答案:

1.  以下是我们需要编排引擎的一些原因:
    *   容器是短暂的，只有自动化系统(指挥者)才能有效地处理它。
    *   出于高可用性的原因，我们希望运行每个容器的多个实例。需要管理的容器数量迅速变得庞大。
    *   为了满足当今互联网的需求，我们需要快速扩大和缩小规模。
    *   与虚拟机相反，容器不会被视为宠物，当它们行为不端时，不会被修复或治愈，而是被视为牛。如果一个不良行为，我们会杀死它并用一个新的实例替换它。编排者快速终止一个不健康的容器，并安排一个新的实例。
2.  以下是容器编排引擎的一些职责:
    *   管理集群中的一组节点
    *   将工作负载调度到具有足够空闲资源的节点
    *   监控节点和工作负载的运行状况
    *   将应用和组件的当前状态与所需状态相协调
    *   提供服务发现和路由
    *   负载平衡请求
    *   通过为机密提供支持来保护可靠的数据

3.  以下是一份(不完整的)管弦乐队名单，按他们的受欢迎程度排序:
    *   库本内斯由谷歌，捐赠给 CNCF
    *   码头工人的群集工具包，即**运营支持系统** ( **操作系统**)
    *   亚马逊的 AWS ECS
    *   微软的 Azure AKS
    *   阿帕奇的 Mesos 也就是 OSS
    *   牧场主的牛
    *   印度大麻公司的游牧民族

# 第十章

1.  正确答案是:

```
$ docker swarm init [--advertise-addr <IP address>]
```

`--advertise-addr`是可选的，只有当您的主机有多个 IP 地址时才需要。

2.  在要删除的工作节点上执行:`$ docker swarm leave`
    在其中一个主节点上执行命令`$ docker node rm -f <node ID>`
    ，其中`<node ID>`是要删除的工作节点的标识。
3.  正确答案是:

```
$ docker network create \
    --driver overlay \
    --attachable \
    front-tier
```

4.  正确答案是:

```
$ docker service create --name web \
 --network front-tier \
 --replicas 5 \
 -p 3000:80 \
 nginx:alpine
```

5.  正确答案是:

```
$ docker service update --replicas 3 web
```

# 破产重组保护

1.  零停机意味着当更新一个服务时，比如从版本 1 到版本 2，这个服务所属的应用一直保持运行。应用在任何时候都不会中断或不起作用。
2.  Docker SwarmKit 使用滚动更新来实现零停机。每个服务都在多个实例中运行，以实现高可用性。当滚动更新发生时，整个服务实例集的小批量被新版本替换。这发生在大多数服务实例启动并运行以服务传入请求的时候。
3.  容器映像是不可变的。也就是说，一旦创建，它们就永远无法更改。当容器化的应用或服务需要更新时，会创建一个新的容器映像。在滚动更新期间，旧的容器映像会被新的容器映像替换。如果需要回滚，则新映像会被旧映像替换。这可以看作是一个反向更新。只要我们不删除旧的容器映像，我们总是可以通过重用它来返回到这个以前的版本。因为，正如我们前面所说的，映像是不可改变的，我们确实正在回到以前的状态。
4.  Docker 机密在静止时加密；它们被加密存储在 raft 数据库中。秘密也在传输中被加密，因为节点到节点的通信是使用相互的 TLS。
5.  命令应该如下所示:

```
$ docker service update --image acme/inventory:2.1 \
 --update-parallelism 2 \
 --update-delay 60s \
 inventory
```

6.  首先，我们需要去除旧的秘密:

```
$ docker service update --secret-rm MYSQL_PASSWORD inventory
```

然后我们添加新的秘密，并确保我们使用扩展格式，在那里我们可以重新映射秘密的名称，也就是说，秘密的外部和内部名称不必匹配。后一个命令可能如下所示:

```
$ docker service update \
 --secret-add source=MYSQL_PASSWORD_V2,target=MYSQL_PASSWORD \
 inventory
```

# 第十二章

1.  Kubernetes 主节点负责管理集群。所有创建对象的请求、吊舱的调度、`ReplicaSets`的管理等等都发生在主机上。主服务器不在生产或类似生产的集群中运行应用工作负载。
2.  在每个工作节点上，我们都有 kubelet、代理和容器运行时。
3.  答案是肯定的。您不能在 Kubernetes 集群上运行独立的容器。吊舱是这样一个集群中部署的原子单元。
4.  pod 内运行的所有容器共享相同的 Linux 内核网络命名空间。因此，在这些容器内运行的所有进程可以通过`localhost`相互通信，就像直接在主机上运行的进程或应用可以通过`localhost`相互通信一样。
5.  `pause`容器的唯一作用是为容器中运行的容器保留容器的名称空间。
6.  这是一个坏主意，因为 pod 的所有容器都在同一个位置，这意味着它们运行在同一个集群节点上。但是应用的不同组件(即`web`、`inventory,`和`db`)在可伸缩性或资源消耗方面通常有非常不同的要求。`web`组件可能需要根据流量进行缩放，而`db`组件则有其他组件没有的特殊存储要求。如果我们在自己的 pod 中运行每个组件，我们在这方面会更加灵活。
7.  我们需要一种机制来运行集群中一个 pod 的多个实例，并确保运行的 pod 的实际数量始终对应于所需的数量，即使单个 pod 因网络分区或集群节点故障而崩溃或消失。复制集是为任何应用服务提供可伸缩性和自我修复的机制。
8.  每当我们想要更新 Kubernetes 集群中的应用服务而不导致服务停机时，我们都需要部署对象。部署对象向复制集添加滚动更新和回滚功能。

9.  Kubernetes 服务对象用于使应用服务参与服务发现。它们为一组吊舱提供了一个稳定的端点(通常由一个复制集或一个部署来管理)。Kube 服务是抽象的，它定义了一组逻辑的 pods 以及如何访问它们的策略。Kube 服务有四种类型:
    *   **集群 IP** :在只能从集群内部访问的 IP 地址上公开服务；这是一个**虚拟 IP** ( **VIP** )
    *   **节点端口**:在每个集群节点上发布一个 30，000–32767 范围内的端口
    *   **负载平衡器**:这种类型使用云提供商的负载平衡器(例如 AWS 上的 ELB)向外部公开应用服务
    *   **外部名称**:当您需要为集群外部服务(如数据库)定义代理时使用

# 第十三章

1.  假设我们在两个应用服务(web API 和 Mongo DB)的注册表中有一个 Docker 映像，那么我们需要执行以下操作:
    *   使用` StatefulSet`定义 Mongo 数据库的部署；我们把这个部署叫做`db-deployment`。`StatefulSet`应该有一个副本(复制 Mongo DB 有点复杂，不在本书的讨论范围内)。
    *   为`db-deployment.`定义一个名为`db`的类型为`ClusterIP`的 Kubernetes 服务
    *   定义网络应用编程接口的部署；姑且称之为`web-deployment`。让我们将这项服务扩展到三个实例。
    *   为`web-deployment.`定义一个名为`api`的类型为`NodePort`的 Kubernetes 服务
    *   如果我们使用秘密，那么使用`kubectl.`直接在集群中定义那些秘密
    *   使用`kubectl.`部署应用

2.  为了实现应用的第 7 层路由，我们最好使用`IngressController`。`IngressController`是一个反向代理，如 Nginx，它有一个边车在库本内斯服务器应用编程接口上监听相关的更改，并更新反向代理的配置，如果检测到这样的更改，则重新启动它。然后，我们需要在集群中定义入口资源，这些资源定义路由，例如从基于上下文的路由(如`https://example.com/pets `到`<a service name>/<port>`对(如`api/32001`)。在 Kubernetes 创建或更改这个入口对象的时候，`IngressController`的侧车会捡起它并更新代理的路由配置。
3.  假设这是一个**集群内部**库存服务:
    *   当部署 1.0 版本时，我们定义了一个名为`inventory-deployment-blue`的部署，并用标签`color: blue.`来标记吊舱
    *   我们为前面的部署部署了名为`inventory`的类型为`ClusterIP`的 Kubernetes 服务，选择器包含`color: blue.`
    *   当准备部署新版本的支付服务时，我们首先为 2.0 版本的服务定义一个部署，并将其称为`inventory-deployment-green`。我们在豆荚上添加一个标签`color: green`。
    *   我们现在可以对“绿色”服务进行冒烟测试，当一切正常时，我们可以更新库存服务，例如选择器包含`color: green`。
4.  某些类型的信息是机密的，因此应该通过 Kubernetes 机密提供给服务，包括:密码、证书、应用编程接口密钥标识、应用编程接口密钥机密或令牌。
5.  秘密值的来源可以是文件或 base64 编码值。

# 第十四章

1.  要在 AWS 中安装 UCP:

    1.  创建一个包含子网和安全组的 VPC。
    2.  然后调配一个 Linux 虚拟机集群，可能作为自动扩展组的一部分。支持很多 Linux 发行版，比如 CentOS、RHEL、Ubuntu 等等。
    3.  接下来，在每个虚拟机上安装 Docker。
    4.  最后，使用 docker/ucp 映像选择一个要在其上安装 UCP 的虚拟机。
    5.  安装 UCP 后，将其他虚拟机作为工作节点或管理节点加入群集。
2.  云供应商特定的专有解决方案(如 ECS)具有与云供应商提供的其他服务(如日志记录、监控或存储)紧密无缝集成的优势。此外，通常不需要调配和管理基础架构，但这将由提供商自动完成。从积极的一面来看，同样值得注意的是，部署第一个容器化应用通常发生得非常快，这意味着启动障碍非常低。
    另一方面，选择 ECS 等专有服务会将我们锁定在各自云提供商的生态系统中。此外，我们必须接受他们给我们的东西。在 Azure ACS 的情况下，这意味着当选择 Docker Swarm 作为编排引擎时，我们得到了传统的 Docker Swarm，它已经被 Docker 用 SwarmKit 取代很久了。
    如果我们选择基于 Docker Swarm 或 Kubernetes 最新版本的托管或自我管理解决方案，我们将享受各自编排引擎的最新和最大功能。