# 处理系统中的变更、依赖和秘密

在本章中，我们将描述与多个微服务交互的不同元素。

我们将研究如何让服务描述其版本的策略，以便依赖的微服务能够发现它们，并确保它们已经部署了适当的依赖关系。这将允许我们在依赖服务中定义部署顺序，并且如果不是所有的依赖都准备好了，将停止服务的部署。

本章介绍如何定义集群范围内的配置参数，以便可以在多个微服务之间共享这些参数，并使用 Kubernetes ConfigMap 在一个地方进行管理。我们还将学习如何处理属于机密的配置参数，例如加密密钥，团队中的大多数人都不应该访问这些参数。

本章将涵盖以下主题:

*   了解跨微服务的共享配置
*   处理不可告人的秘密
*   定义影响多个服务的新功能
*   处理服务依赖关系

到本章结束时，您将知道如何为安全部署准备依赖服务，以及如何在微服务中包含秘密，这些秘密在部署之外是无法访问的。

# 技术要求

该代码可通过以下网址在 GitHub 上获得:[https://GitHub . com/packt publishing/动手操作 Python 微服务/树/主/第 11 章](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter11)。请注意，该代码是`Chapter10`中代码的扩展，带有本章所述的额外元素。结构是相同的，一个名为`microservices`的子目录包含代码，另一个名为`kubernetes`的子目录包含库本内特斯配置文件。

要安装集群，您需要使用以下命令构建每个单独的微服务:

```
$ cd Chapter11/microservices/
$ cd rsyslog
$ docker-compose build
...
$ cd frontend
$ ./build-test.sh
...
$ cd thoughts_backend
$./build-test.sh
...
$ cd users_backend
$ ./build-test.sh
... 
```

这将构建所需的服务。

Note that we use the `build-test.sh `script. We will explain how it works in this chapter.

然后，创建`namespace`示例，并使用`Chapter11/kubernetes`子目录中的配置启动 Kubernetes 集群:

```
$ cd Chapter11/kubernetes
$ kubectl create namespace example
$ kubectl apply --recursive -f .
...
```

这会将微服务部署到集群中。

The code included in `Chapter11` has some issues and **won't** deploy correctly until it is fixed. This is the expected behavior. During the chapter, we will explain the two problems: the secrets not getting configured, and the dependency for Frontend not getting fulfilled, stopping it from starting.

Keep reading the chapter to find the problems described. The solution is proposed as an assessment.

为了能够访问不同的服务，您需要更新您的`/etc/hosts`文件，以包括以下几行:

```
127.0.0.1 thoughts.example.local
127.0.0.1 users.example.local
127.0.0.1 frontend.example.local
```

这样，您将能够访问本章的服务。

# 了解跨微服务的共享配置

一些配置可能对几个微服务通用。在我们的示例中，我们为数据库连接复制了相同的值。我们可以使用 ConfigMap 并在不同的部署之间共享它，而不是重复每个部署文件上的值。

We've seen how to add ConfigMap to include files in [Chapter 10](10.html), *Monitoring Logs and Metrics*, under the *Setting up metrics *section. It was used for a single service, though.

配置映射是一组键/值元素。它们可以作为环境变量或文件添加。在下一节中，我们将添加一个包含集群中所有共享变量的通用配置文件。

# 添加配置映射文件

`configuration.yaml`文件包含系统的常用配置。它位于`Chapter11/kubernetes`子目录中:

```
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: shared-config
  namespace: example
data:
  DATABASE_ENGINE: POSTGRES
  POSTGRES_USER: postgres
  POSTGRES_HOST: "127.0.0.1"
  POSTGRES_PORT: "5432"
  THOUGHTS_BACKEND_URL: http://thoughts-service
  USER_BACKEND_URL: http://users-service
```

与数据库相关的变量`DATABASE_ENGINE`、`POSTGRES_USER`、`POSTGRES_HOST`和`POSTGRES_PORT`在思想后端和用户后端之间共享。

The `POSTGRES_PASSWORD` variable is a secret. We will describe this later in this chapter in the *Handling Kubernetes secrets *section.

前端服务中使用了`THOUGHTS_BACKEND_URL`和`USER_BACKEND_URL`变量。不过，它们在集群中很常见。任何想要连接到思想后端的服务都应该使用与`THOUGHTS_BACKEND_URL`中描述的相同的网址。

即使它只在一个单一的服务中使用，到目前为止，它符合系统范围内的变量描述，应该包含在一般配置中。

One of the advantages of having a shared repository for variables is to consolidate them.

While creating multiple services and developing them independently, it is quite common to end up using the same information, but in two slightly different ways. Teams developing independently won't be able to share information perfectly, and this kind of mismatch will happen.

For example, one service can describe an endpoint as `URL=http://service/api`, and another service using the same endpoint will describe it as `HOST=service PATH=/api`. The code of each service handles the configuration differently, though they connect to the same endpoint. This makes it more difficult to change the endpoint in a unified way, as it needs to be changed in two or more places, in two ways.

A shared place is a good way to first detect these problems, as they normally go undetected if each service keeps its own independent configuration, and then to adapt the services to use the same variable, reducing the complexity of the configuration.

在我们的例子中，配置映射的名称是`shared-config`，正如元数据中定义的那样，并且像任何其他 Kubernetes 对象一样，它可以通过`kubectl`命令进行管理。

# 使用 kubectl 命令

可以使用常用的一组`kubectl`命令来检查配置图信息。这允许我们发现群集中已定义的配置映射实例:

```
$ kubectl get configmap -n example shared-config
NAME               DATA AGE
shared-config      6    46m
```

请注意 ConfigMap 包含的键或变量的数量是如何显示的；在这里，是`6`。要查看配置地图的内容，请使用`describe`:

```
$ kubectl describe configmap -n example shared-config
Name: shared-config
Namespace: example
Labels: <none>
Annotations: kubectl.kubernetes.io/last-applied-configuration:
 {"apiVersion":"v1","data":{"DATABASE_ENGINE":"POSTGRES","POSTGRES_HOST":"127.0.0.1","POSTGRES_PORT":"5432","POSTGRES_USER":"postgres","THO...

Data
====
POSTGRES_HOST:
----
127.0.0.1
POSTGRES_PORT:
----
5432
POSTGRES_USER:
----
postgres
THOUGHTS_BACKEND_URL:
----
http://thoughts-service
USER_BACKEND_URL:
----
http://users-service
DATABASE_ENGINE:
----
POSTGRES
```

如果您需要更改配置映射，您可以使用`kubectl edit`命令，或者更好的是，使用以下命令更改`configuration.yaml`文件并重新应用它:

```
$ kubectl apply -f kubernetes/configuration.yaml
```

这将覆盖所有值。

The configuration won't be applied automatically to the Kubernetes cluster. You'll need to redeploy the pods affected by the changes. The easiest way is to delete the affected pods and allow the deployment to recreate them.

On the other hand, if Flux is configured, it will redeploy the dependent pods automatically. Keep in mind that a change in ConfigMap (referenced in all pods) will trigger a redeploy on all pods in that situation.

我们现在将看到如何向部署中添加配置映射。

# 向部署添加配置映射

一旦配置映射到位，它就可以用于与不同的部署共享其变量，从而维护一个中心位置来更改变量并避免重复。

让我们看看微服务(思想后端、用户后端和前端)的每个部署是如何利用`shared-config`配置图的。

# 想法后端配置映射配置

思想后端部署定义如下:

```
spec:
    containers:
        - name: thoughts-backend-service
          image: thoughts_server:v1.5
          imagePullPolicy: Never
          ports:
              - containerPort: 8000
          envFrom:
              - configMapRef:
                    name: shared-config
          env:
              - name: POSTGRES_DB
                value: thoughts
          ...
```

完整的`shared-config`配置图将被注入吊舱。请注意，这包括以前在吊舱中不可用的`THOUGHTS_BACKEND_URL`和`USER_BACKEND_URL`环境变量。可以添加更多的环境变量。这里，我们留下了`POSTGRES_DB`而不是将其添加到配置图中。

我们可以用吊舱中的`exec`来确认。

Note that to be able to connect the secret, it should be properly configured. Refer to the *Handling Kubernetes secrets* section.

要检查容器内部，检索容器名称并在其中使用`exec`，如以下命令所示:

```
$ kubectl get pods -n example
NAME                              READY STATUS  RESTARTS AGE
thoughts-backend-5c8484d74d-ql8hv 2/2   Running 0        17m
...
$ kubectl exec -it thoughts-backend-5c8484d74d-ql8hv -n example /bin/sh
Defaulting container name to thoughts-backend-service.
/opt/code $ env | grep POSTGRES
DATABASE_ENGINE=POSTGRESQL
POSTGRES_HOST=127.0.0.1
POSTGRES_USER=postgres
POSTGRES_PORT=5432
POSTGRES_DB=thoughts
/opt/code $ env | grep URL
THOUGHTS_BACKEND_URL=http://thoughts-service
USER_BACKEND_URL=http://users-service
```

`env`命令返回所有的环境变量，但是有很多是由 Kubernetes 自动添加的。

# 用户后端配置映射配置

用户后端配置类似于我们刚才看到的前一种配置:

```
spec:
    containers:
        - name: users-backend-service
          image: users_server:v2.3
          imagePullPolicy: Never
          ports:
              - containerPort: 8000
          envFrom:
              - configMapRef:
                    name: shared-config
          env:
              - name: POSTGRES_DB
                value: thoughts
          ...
```

`POSTGRES_DB`的值与思想后端中的值相同，但我们将其留在这里是为了展示如何添加更多的环境变量。

# 前端 ConfigMap 配置

前端配置仅使用配置映射，因为不需要额外的环境变量:

```
spec:
    containers:
        - name: frontend-service
          image: thoughts_frontend:v3.7
          imagePullPolicy: Never
          ports:
              - containerPort: 8000
          envFrom:
              - configMapRef:
                    name: shared-config
```

前端盒现在还将包含与数据库连接的信息，这是它不需要的。这对于大多数配置参数来说都没问题。

You can also use multiple ConfigMaps to describe different groups of configurations, if necessary. It is simpler to handle them in a big bucket with all the configuration parameters, though. This will help to catch duplicated parameters and ensure that you have all the required parameters in all microservices.

然而，一些配置参数必须小心处理，因为它们是敏感的。例如，我们从`shared-config`配置图中省略了`POSTGRES_PASSWORD`变量。这样我们就可以登录数据库了，不应该和其他参数存储在任何文件上，以免意外暴露。

为了处理这种信息，我们可以使用 Kubernetes 秘密。

# 处理不可告人的秘密

秘密是一种特殊的配置。它们需要受到保护，以免被使用它们的其他微服务读取。它们通常是敏感数据，如私钥、加密密钥和密码。

请记住，读取秘密是一个有效的操作。毕竟，它们需要被使用。秘密与其他配置参数的区别在于，它们需要受到保护，因此只有授权的来源才能读取它们。

秘密应该由环境注入。这要求代码能够检索配置机密，并为当前环境使用正确的配置机密。它还避免将秘密存储在代码中。

Remember *never* to commit production secrets in your Git repositories. The Git tree means that, even if it's deleted, the secret is retrievable. This includes the GitOps environment.

Also, use different secrets for different environments. The production secrets require more care than the ones in test environments.

在我们的 Kubernetes 配置中，授权来源是使用它们的微服务，以及通过`kubectl`访问的系统管理员。

让我们看看如何管理这些秘密。

# 在忽必烈心中隐藏秘密

Kubernetes 将秘密作为一种特定的配置映射值来处理。它们可以在系统中定义，然后以配置图的方式应用。与一般配置图的区别在于信息在内部受到保护。虽然可以通过`kubectl`访问它们，但它们受到保护，不会意外暴露。

可以通过`kubectl`命令在集群中创建一个秘密。它们不应该是通过文件和 GitOps 或 Flux 创建的*，而应该是手动创建的。这避免了将秘密存储在 GitOps repo 下。*

 *需要秘密操作的吊舱将在它们的部署文件中指明。在 GitOps 源代码控制下存储是安全的，因为它不存储秘密，只存储对秘密的引用。当吊舱被部署时，它将使用正确的参考和解码秘密。

Logging into the pod will grant you access to the secret. This is normal, since, inside the pod, the application needs to read its value. Granting access to execute commands in the pod will grant them access to the secrets inside, so keep it in mind. You can read Kubernetes documentation about the best practices of the secrets to understand and adjust depending on your requirements ([https://kubernetes.io/docs/concepts/configuration/secret/#best-practices](https://kubernetes.io/docs/concepts/configuration/secret/#best-practices)).

现在我们知道如何处理它们，让我们看看如何创造这些秘密。

# 创造秘密

让我们在库本内斯创造秘密。我们将存储以下秘密:

*   PostgreSQL 密码
*   签名和验证请求的公钥和私钥

我们将把它们存储在可以有多个密钥的同一个 Kubernetes 秘密中。以下命令显示了如何生成一对密钥:

```
$ openssl genrsa -out private_key.pem 2048
Generating RSA private key, 2048 bit long modulus
........+++
.................+++
e is 65537 (0x10001)
$ openssl rsa -in private_key.pem -outform PEM -pubout -out public_key.pub
writing RSA key
$ ls 
private_key.pem public_key.pub
```

这些钥匙是你独有的。我们将使用它们来替换前面章节中存储的示例键。

# 将秘密存储在集群中

将秘密存储在集群中`thoughts-secrets`秘密下。请记住将其存储在`example`命名空间中:

```
$ kubectl create secret generic thoughts-secrets --from-literal=postgres-password=somepassword --from-file=private_key.pem --from-file=public_key.pub -n example
```

您可以列出命名空间中的秘密:

```
$ kubectl get secrets -n example
NAME             TYPE   DATA AGE
thoughts-secrets Opaque 3    41s
```

你可以描述这些秘密来获得更多信息:

```
$ kubectl describe secret thoughts-secrets -n example
Name: thoughts-secrets
Namespace: default
Labels: <none>
Annotations: <none>

Type: Opaque

Data
====
postgres-password: 12 bytes
private_key.pem: 1831 bytes
public_key.pub: 408 bytes
```

您可以获取秘密的内容，但是检索的数据是以 Base64 编码的。

Base64 is an encoding scheme that allows you to transform binary data into text and vice versa. It is widely used. This allows you to store any binary secret, not only text. It also means that the secrets are not displayed in plain text when retrieved, adding a small layer of protection in cases such as unintentional display in screens.

要获取秘密，请使用通常的`kubectl get`命令，如下所示。我们使用`base64`命令对其进行解码:

```
$ kubectl get secret thoughts-secrets -o yaml -n example
apiVersion: v1
data:
 postgres-password: c29tZXBhc3N3b3Jk
 private_key.pem: ...
 public_key.pub: ...
$ echo c29tZXBhc3N3b3Jk | base64 --decode
somepassword
```

同样，如果您编辑一个秘密来更新它，输入应该用 Base64 编码。

# 秘密部署配置

我们需要在部署配置中配置密码用法，这样密码就可以在所需的 pod 中使用。例如，在用户后端`deployment.yaml`配置文件中，我们有以下代码:

```
spec:
    containers:
    - name: users-backend-service
      ...
      env:
      ...
      - name: POSTGRES_PASSWORD
        valueFrom:
          secretKeyRef:
            name: thoughts-secrets
            key: postgres-password
        volumeMounts:
        - name: sign-keys
          mountPath: "/opt/keys/"

    volumes:
    - name: sign-keys
      secret:
        secretName: thoughts-secrets
        items:
        - key: public_key.pub
          path: public_key.pub
        - key: private_key.pem
          path: private_key.pem
```

我们创建了直接来自秘密的`POSTGRES_PASSWORD`环境变量。我们还创建了一个名为`sign-keys`的卷，其中包含两个密钥作为文件，`public_key.pub`和`private_key.pem`。它位于`/opt/keys/`路径上。

以类似的方式，思想后端的`deployment.yaml`文件包含秘密，但只有 PostgreSQL 密码和`public_key.pub`。请注意，没有添加私钥，因为思想后端不需要它，并且它不可用。

对于前端，只需要公钥。现在，让我们建立如何检索秘密。

# 通过应用程序检索秘密

对于`POSTGRES_PASSWORD`环境变量，我们不需要改变任何东西。它已经是一个环境变量，代码正在从中提取它。

但是对于作为文件存储的秘密，我们需要从适当的位置检索它们。存储为文件的秘密是签署身份验证头的关键。所有微服务都需要公共文件，只有用户后端需要私钥。

现在，让我们看看用户后端的`config.py`文件:

```
import os
PRIVATE_KEY = ...
PUBLIC_KEY = ...

PUBLIC_KEY_PATH = '/opt/keys/public_key.pub'
PRIVATE_KEY_PATH = '/opt/keys/private_key.pem'

if os.path.isfile(PUBLIC_KEY_PATH):
    with open(PUBLIC_KEY_PATH) as fp:
        PUBLIC_KEY = fp.read()

if os.path.isfile(PRIVATE_KEY_PATH):
    with open(PRIVATE_KEY_PATH) as fp:
        PRIVATE_KEY = fp.read()
```

当前键仍然作为默认值存在。当秘密文件没有装入时，它们将用于单元测试。

It is worth saying it again, but please *do not* use any of these keys. These are for running tests only and available to anyone that has access to this book.

如果`/opt/keys/`路径中的文件存在，它们将被读取，并且内容将被存储在适当的常数中。用户后端需要公钥和私钥。

在思想后端`config.py `文件中，我们只检索公钥，如以下代码所示:

```
import os
PUBLIC_KEY = ...

PUBLIC_KEY_PATH = '/opt/keys/public_key.pub'

if os.path.isfile(PUBLIC_KEY_PATH):
    with open(PUBLIC_KEY_PATH) as fp:
        PUBLIC_KEY = fp.read()
```

前端服务在`settings.py`文件中添加公钥:

```
TOKENS_PUBLIC_KEY = ...

PUBLIC_KEY_PATH = '/opt/keys/public_key.pub'

if os.path.isfile(PUBLIC_KEY_PATH):
    with open(PUBLIC_KEY_PATH) as fp:
        TOKENS_PUBLIC_KEY = fp.read()
```

这种配置使秘密对应用程序可用，并关闭秘密值的循环。现在，微服务集群使用来自秘密值的签名密钥，这是存储敏感数据的安全方式。

# 定义影响多个服务的新功能

我们讨论了单个微服务范围内的变更请求。但是，如果我们需要部署一个在两个或多个微服务中工作的功能，该怎么办呢？

与整体方法相比，这些类型的功能应该相对较少，并且是微服务开销的主要原因之一。在单块中，这种情况是不可能的，因为所有东西都包含在单块的壁内。

同时，在微服务架构中，这是一个复杂的变化。这涉及到驻留在两个不同回购中的每个相关微服务上的至少两个独立特性。很可能是由两个不同的团队开发，或者至少不同的人负责每个功能。

# 一次部署一个变更

为了确保这些特性可以顺利部署，一次一个，它们需要保持向后兼容性。这意味着您需要能够生活在服务 A 已经部署的中间阶段，而不是服务 b。微服务中的每个变化都需要尽可能小，以最小化风险，并且应该一次引入一个变化。

为什么我们不同时部署它们呢？因为同时释放两个微服务是危险的。首先，部署不是即时的，因此会有过时的服务发送或接收系统不准备处理的呼叫的时刻。这会产生错误，影响您的客户。

但是有可能出现这样的情况，其中一个微服务不正确，需要回滚。然后，系统处于不一致的状态。依赖的微服务也需要回滚。这本身是有问题的，但是当在调试这个问题的过程中，两个微服务都被卡住，并且在问题得到修复之前无法更新时，这可能会使事情变得更糟。

在健康的微服务环境中，部署会经常发生。因为另一个服务需要工作而不得不停止一个微服务的管道是一个糟糕的处境，它只会增加压力和紧迫性。

Remember that we talked about the speed of deployment and change. Deploying small increments often is the best way to ensure that each deployment will be of high quality. The constant flow of incremental work is very important.

Interrupting this flow due to an error is bad, but the effect multiplies quickly if the inability to deploy affects the pace of multiple microservices.

同时部署多个服务也可能造成死锁，两个服务都需要工作来解决这种情况。这使得解决问题的开发和时间变得复杂。

需要进行分析来确定哪个微服务依赖于另一个，而不是同时部署。很多时候，这是显而易见的。在我们的例子中，前端依赖于思想后端，所以任何涉及到它们的变化都需要从思想后端开始，然后转移到前端。

Actually, the Users Backend is a dependency of both, so assuming there's a change that affects the three of them, you'll need to first change the Users Backend, then the Thoughts Backend, and finally the Frontend.

请记住，有时部署可能需要跨服务移动不止一次。例如，让我们假设身份验证头的签名机制发生了变化。过程应该如下:

1.  在用户后端实现新的身份验证系统，但通过配置更改继续使用旧系统生成令牌。到目前为止，旧的身份验证过程仍在群集中使用。
2.  更改思想后端，以允许使用旧的和新的身份验证系统。请注意，它尚未激活。
3.  将前端更改为同时使用两种身份验证系统。尽管如此，在这一点上，新系统还没有使用。
4.  更改用户后端的配置以生成新的身份验证令牌。现在是新系统开始使用的时候了。在部署过程中，可能会生成一些旧的系统令牌。
5.  用户后端和前端将使用系统中的任何令牌，无论是新的还是旧的。旧代币将随着时间的推移而消失，因为它们会过期。新令牌是唯一正在创建的令牌。
6.  作为一个可选阶段，旧的身份验证系统可以从系统中删除。这三个系统可以删除它们，而没有任何依赖性，因为此时不使用该系统。

在流程的任何一步，服务都不会中断。每个单独的变化都是安全的。这个过程正在慢慢地使整个系统进化，但是如果出现问题，每个单独的步骤都是可逆的，并且服务不会中断。

系统倾向于通过增加新的特性来开发，通常会有一个清理阶段。通常，系统长期使用不推荐使用的功能，即使该功能没有在任何地方使用。

We will talk a bit more about clean-up in [Chapter 12](12.html), *Collaborating and Communicating across Teams*.

配置更改也可能需要此过程。在该示例中，更改签名身份验证标头所需的私钥需要以下步骤:

1.  让思想后端和前端能够处理多个公钥。这是一个前提，也是一个新特点。
2.  在思想后端中更改处理过的密钥，以同时拥有旧的和新的公钥。到目前为止，系统中没有使用新密钥签名的标头。
3.  更改前端中的手柄键，使其既有旧的也有新的。尽管如此，系统中仍然没有用新密钥签名的头。
4.  更改用户后端的配置以使用新的私钥。从现在开始，系统中有用新私钥签名的头。其他微服务能够处理它们。
5.  系统仍然接受用旧密钥签名的头。等待一段安全时间，以确保所有旧标头都已过期。
6.  删除用户后端中旧密钥的配置。

步骤 2 到 6 可以每隔几个月重复一次，以使用新的密钥。

这个过程被称为**密钥旋转**，它被认为是一个很好的安全实践，因为它缩短了密钥有效时的寿命，减少了系统易受密钥泄露影响的时间窗口。为了简单起见，我们没有在我们的示例系统中实现它，但是这样做是一个推荐的练习。尝试更改示例代码来实现这个键旋转示例！

完整的系统功能可能涉及多个服务和团队。为了帮助协调系统的依赖关系，我们需要知道某个服务依赖关系何时被部署并准备就绪。我们将在[第 12 章](12.html)、*中讨论团队间的通信，但是我们可以通过使服务 API 明确描述部署了哪个版本的服务来以编程方式提供帮助，正如我们将在*处理服务依赖关系*一节中讨论的那样。*

如果刚刚部署的新版本出现问题，可以通过回滚快速恢复部署。

# 回滚微服务

回滚是将其中一个微服务快速回滚到以前版本的过程。

这个过程可以在刚发布的新版本出现灾难性错误时触发，所以可以很快解决。鉴于该版本目前已经兼容，这可以在很短的反应时间内放心地完成。通过 GitOps 原则，可以执行`revert`提交来恢复旧版本。

The `git revert` command allows you to create a commit that undoes another, applying the same changes in reverse.

This is a quick way to undo a particular change, and to allow later to *revert the revert* and reintroduce the changes. You can check the Git documentation for more details ([https://git-scm.com/docs/git-revert](https://git-scm.com/docs/git-revert)[).](https://git-scm.com/docs/git-revert)

考虑到继续前进的战略方法，回滚是一种临时措施，虽然已经到位，但将停止微服务中的新部署。应该尽快创建一个解决导致灾难性部署的 bug 的新版本，以便保持发布的正常流程。

随着部署越来越频繁，检查越来越到位，回滚将越来越不常见。

# 处理服务依赖关系

为了允许服务检查它们的依赖项是否有正确的版本，我们将让服务通过 RESTful 端点公开它们的版本。

我们将遵循 GitHub 中可用的思想后端中的示例，网址为:[https://GitHub . com/PacktPublishing/动手 Docker-for-micro service-with-Python/tree/master/chapter 11/micro service/ideas _ 后端](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter11/microservices/thoughts_backend)。

检查前端中的版本是否可用(https://github . com/PacktPublishing/手动-Docker-for-microservice-with-Python/tree/master/chapter 11/microservice/前端)。

这个过程的第一步是正确定义每个服务的版本。

# 服务版本化

为了清楚地了解我们软件的进展，我们需要命名要部署的不同版本。当我们使用`git`来跟踪变更时，系统中的每个提交都有一个单独的提交 ID，但是它不遵循任何特定的模式。

为了赋予它意义并对它们进行排序，我们需要开发一个版本模式。制作版本模式有多种方式，包括按发布日期(Ubuntu 使用这个)或按`major.minor.patch`。

在任何地方都有相同的版本控制方案有助于跨团队开发共同的语言和理解。这也有助于管理层理解这些变化——无论是从发布时间，还是从变化速度来看。与您的团队商定一个在您的组织中有意义的版本方案，并在所有服务中遵循它。

对于这个例子，我们将使用`vMajor.Minor`模式，用户后端的版本为`v2.3`。

软件版本控制中最常见的模式是语义版本控制。这种版本控制模式对于包和面向客户的 API 很有用，但是对于内部微服务 API 就没那么有用了。让我们看看它的特点是什么。

# 语义版本控制

语义版本化赋予每个不同版本号的变化以意义。这使得很容易理解版本之间的变化范围，以及在依赖系统上进行更新是否有风险。

语义版本化用三个数字定义每个版本:主要、次要和补丁，通常描述为`major.minor.patch` *。*

增加这些数字中的任何一个都有特定的含义，如下所示:

*   增加主要数字会产生向后不兼容的变化。
*   增加次要数量会增加新功能，但会保持向后兼容性。
*   增加补丁数量可以修复 bug，但不会增加任何新功能。

例如，Python 在这个模式下工作如下:

*   Python 3 包含了与 Python 2 的兼容性更改。
*   与 Python 3.6 相比，Python 3.6 版本引入了新功能。
*   与 Python 3.7.3 相比，Python 3.7.4 增加了安全性和错误修复。

这种版本控制方案在与外部合作伙伴交流时非常有用，对于大版本和标准包非常有用。但是对于微服务中的小的增量变化，它不是很有用。

正如我们在前面几章中所讨论的，要交付的持续集成的关键是进行非常小的更改。它们不应该破坏向后兼容性，但是随着时间的推移，旧的特性将会被删除。每个微服务都以受控的方式与其他服务协同工作。与外包装相比，没有必要有这么强的功能标签。服务的消费者是集群中受到严格控制的其他微服务。

Some projects are abandoning semantic versioning due to this change in operation. For example, the Linux kernel stopped using semantic versioning to produce new versions without any particular meaning ([http://lkml.iu.edu/hypermail/linux/kernel/1804.1/06654.html](http://lkml.iu.edu/hypermail/linux/kernel/1804.1/06654.html)), as changes from one version to the next are relatively small.

Python will also treat version 4.0 as *the version that goes after 3.9*, without major changes like Python 3 had ([http://www.curiousefficiency.org/posts/2014/08/python-4000.html](http://www.curiousefficiency.org/posts/2014/08/python-4000.html)).

这就是为什么在内部，语义版本化是*而不是*推荐的原因。保持一个类似的版本方案可能是有用的，但是不要强迫它进行兼容性更改，只是不断增加的数字，不要对何时更改次要或主要版本有具体的要求。

不过，从外部来看，版本号可能仍有营销意义。对于外部可访问的端点，使用语义版本控制可能会很有趣。

一旦决定了服务的版本，我们就可以在公开这些信息的端点上工作。

# 添加版本端点

要部署的版本可以从 Kubernetes 部署或 GitOps 配置中读取。但是有一个问题。有些配置可能会误导或不是唯一指向一个图像。例如，`latest`标签可能在不同的时间代表不同的容器，因为它被覆盖了。

此外，访问 Kubernetes 配置或 GitOps repo 也存在问题。对于开发人员来说，也许这种配置是可用的，但是它们不适合微服务(也不应该是)。

为了让集群中的其余微服务发现服务的版本，最好的方法是在 RESTful API 中显式创建一个版本端点。服务版本的发现是被授权的，因为它使用了它将在任何其他请求中使用的相同接口。让我们看看如何实现它。

# 获取版本

为了提供版本，我们首先需要将它记录到服务中。

正如我们之前讨论的，版本存储为一个 Git 标签。这将是我们在版本的佳能。我们还将添加提交的 Git SHA-1，以避免任何差异。

The SHA-1 is a unique ID that identifies each commit. It's produced by hashing the Git tree, so that it's able to capture any change—either the content or the tree history. We will use the full SHA-1 of 40 characters, even though sometimes it is abbreviated to eight or less.

提交 SHA-1 可以通过以下命令获得:

```
$ git log --format=format:%H -n 1
```

这将打印最后一个提交信息，并且只打印带有`%H`描述符的 SHA。

为了获得这个提交所引用的标签，我们将使用`git-describe`命令:

```
$ git describe --tags
```

基本上，`git-describe`找到与当前提交最接近的标签。如果这个提交由一个标记来标记，就像我们的部署应该做的那样，它会返回标记本身。如果不是，它会在标记后面加上关于提交的额外信息，直到它到达当前提交。以下代码显示了如何使用`git describe`，具体取决于提交的代码版本。注意与标签无关的代码如何返回最接近的标签和额外的数字:

```
$ # in master branch, 17 commits from the tag v2.3
$ git describe
v2.3-17-g2257f9c
$ # go to the tag
$ git checkout v2.3
$ git describe
v2.3
```

这总是返回一个版本，并允许我们一眼检查当前提交中的代码是否在`git`中标记。

Anything that gets deployed to an environment should be tagged. Local development is a different matter, as it consists of code that is not ready yet.

我们可以以编程方式存储这两个值，允许我们自动存储，并将它们包含在 Docker 映像中。

# 将版本存储在图像中

我们希望在图像中有可用的版本。因为图像是不可变的，所以在构建过程中这样做是目标。这里我们需要克服的限制是 Dockerfile 进程不允许我们在主机上执行命令，只能在容器内部执行。我们需要在构建时将这些值注入 Docker 映像。

A possible alternative is to install Git inside the container, copy the whole Git tree, and obtain the values. This is usually discouraged because installing Git and the full source tree adds a lot of space to the container, something that is worse. During the build process, we already have Git available, so we just need to be sure to inject it externally, which is easy to do with a build script.

传递该值最简单的方法是通过`ARG`参数。作为构建过程的一部分，我们将把它们转换成环境变量，这样它们将像配置的任何其他部分一样容易获得。让我们看看下面代码中的 Dockerfile:

```
# Prepare the version
ARG VERSION_SHA="BAD VERSION"
ARG VERSION_NAME="BAD VERSION"
ENV VERSION_SHA $VERSION_SHA
ENV VERSION_NAME $VERSION_NAME
```

我们接受一个`ARG`参数，然后通过`ENV`参数将其转换为环境变量。为了简单起见，两者有相同的名称。`ARG`参数对于拐角情况有默认值。

在我们使用`build.sh`脚本构建版本之后，这使得版本可用(在容器内部)，该脚本获取值并调用`docker-compose`以版本作为参数构建，使用以下步骤:

```
# Obtain the SHA and VERSION
VERSION_SHA=`git log --format=format:%H -n 1`
VERSION_NAME=`git describe --tags`
# Build using docker-compose with arguments
docker-compose build --build-arg VERSION_NAME=${VERSION_NAME} --build-arg VERSION_SHA=${VERSION_SHA}
# Tag the resulting image with the version
docker tag thoughts_server:latest throughs_server:${VERSION_NAME}
```

在构建过程之后，版本作为容器内的标准环境变量可用。

We included a script (`build-test.sh `) in each of the microservices in this chapter  (for example, [https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter11/microservices/thoughts_backend/build-test.sh](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter11/microservices/thoughts_backend/build-test.sh)). This mocks the SHA-1 and version name to create a synthetic version for tests. It sets up the `v2.3` version for the Users Backend and `v1.5` for the Thoughts Backend. These will be used for examples in our code. 

Check that the Kubernetes deployments include those versions (for example, the [https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter11/microservices/thoughts_backend/docker-compose.yaml#L21](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter11/microservices/thoughts_backend/docker-compose.yaml#L21) image is the `v1.5` version).

此外，`VERSION_NAME`也可以作为脚本的参数来自 CI 管道。为此，您需要替换脚本以从外部接受它，如`build-ci.sh`脚本所示:

```
#!/bin/bash
if [ -z "$1" ]
  then
    # Error, not version name
    echo "No VERSION_NAME supplied"
    exit -1
fi

VERSION_SHA=`git log --format=format:%H -n 1`
VERSION_NAME=$1

docker-compose build --build-arg VERSION_NAME=${VERSION_NAME} --build-arg VERSION_SHA=${VERSION_SHA}
docker tag thoughts_server:latest throughs_server:${VERSION_NAME}
```

这些脚本的所有版本都包括以`VERSION_NAME`作为标签的图像的标签。

我们可以在 Python 代码中检索容器内部版本的环境变量，在端点中返回它们，使版本可以通过外部 API 轻松访问。

# 实现版本端点

在`admin_namespace.py`文件中，我们将使用以下代码创建一个新的`Version`端点:

```
import os

@admin_namespace.route('/version/')
class Version(Resource):

    @admin_namespace.doc('get_version')
    def get(self):
        '''
        Return the version of the application
        '''
        data = {
            'commit': os.environ['VERSION_SHA'],
            'version': os.environ['VERSION_NAME'],
        }

        return data
```

好了，现在这段代码非常简单。它使用`os.environ`来检索构建期间作为配置参数注入的环境变量，并返回一个带有提交 SHA-1 和标签的字典(描述为版本)。

该服务可以在本地构建和运行，使用`docker-compose`。要测试对`/admin/version`中端点的访问并进行检查，请执行以下步骤:

```
$ cd Chapter11/microservices/thoughts_backend
$ ./build.sh
...
Successfully tagged thoughts_server:latest
$ docker-compose up -d server
Creating network "thoughts_backend_default" with the default driver
Creating thoughts_backend_db_1 ... done
Creating thoughts_backend_server_1 ... done
$ curl http://localhost:8000/admin/version/
{"commit": "2257f9c5a5a3d877f5f22e5416c27e486f507946", "version": "tag-17-g2257f9c"}
```

由于版本可用，我们可以更新自动生成的文档来显示正确的值，如`app.py`所示:

```
import os
...
VERSION = os.environ['VERSION_NAME']
...

def create_app(script=False):
    ...
    api = Api(application, version=VERSION, 
              title='Thoughts Backend API',
              description='A Simple CRUD API')
```

因此，该版本会在自动斯瓦格文档中正确显示。一旦微服务的版本可以通过应用编程接口中的端点访问，其他外部服务就可以访问它来发现版本并使用它。

# 检查版本

能够通过应用编程接口检查版本允许我们以编程方式轻松访问版本。这可以用于多种目的，比如生成一个仪表板，显示在不同环境中部署的不同版本。但是我们将探索引入服务依赖的可能性。

微服务在启动时，可以检查它所依赖的服务，还可以检查它们是否高于预期版本。如果不是，就不会开始。这避免了在更新依赖项之前部署一个依赖服务时的配置问题。这可能发生在复杂的系统中，在这些系统中，部署没有很好的协调。

为了检查版本，在`start_server.sh`中启动服务器时，我们将首先调用一个检查依赖关系的小脚本。如果不可用，将产生错误并停止。我们将检查前端是否有思想后端的可用版本，甚至更高。

我们将在示例中调用的脚本称为`check_dependencies_services.py`，它在`start_server.sh`中被调用用于前端。

`check_dependencies_services`脚本可以分为三个部分:所需依赖项的列表；对一种依赖性的检查；和检查每个依赖关系的主要部分。让我们来看看这三个部分。

# 所需版本

第一部分描述了每个依赖项和所需的最低版本。在我们的示例中，我们规定`thoughts_backend`需要是版本`v1.6`或更高版本:

```
import os

VERSIONS = {
    'thoughts_backend': 
        (f'{os.environ["THOUGHTS_BACKEND_URL"]}/admin/version',
         'v1.6'),
}
```

这将重用环境变量`THOUGHTS_BACKEND_URL`，并使用特定的版本路径完成网址。

主要部分通过描述的所有依赖项来检查它们。

# 主要功能

主函数遍历`VERSIONS`字典，并对每个字典执行以下操作:

*   调用端点
*   分析结果并获取版本
*   调用`check_version`查看是否正确

如果失败，将以`-1`状态结束，因此脚本报告为失败。这些步骤通过以下代码执行:

```
import requests

def main():
    for service, (url, min_version) in VERSIONS.items():
        print(f'Checking minimum version for {service}')
        resp = requests.get(url)
        if resp.status_code != 200:
            print(f'Error connecting to {url}: {resp}')
            exit(-1)

        result = resp.json()
        version = result['version']
        print(f'Minimum {min_version}, found {version}')
        if not check_version(min_version, version):
            msg = (f'Version {version} is '
                    'incorrect (min {min_version})')
            print(msg)
            exit(-1)

if __name__ == '__main__':
    main()
```

主功能还会打印一些消息来帮助理解不同的阶段。为了调用版本端点，它使用`requests`包，并期望得到一个`200`状态代码和一个可解析的 JSON 结果。

Note that this code iterates through the `VERSION` dictionary. So far, we only added one dependency, but the User Backend is another dependency and can be added. It's left as an exercise to do.

版本字段将在`check_version`功能中检查，我们将在下一节中看到。

# 检查版本

`check_version`功能检查返回的当前版本是否高于或等于最低版本。为了简化，我们将使用`natsort`包对版本进行排序，然后检查最低版本。

You can check out the `natsort` full documentation ([https://github.com/SethMMorton/natsort](https://github.com/SethMMorton/natsort)). It can sort a lot of natural strings and can be used in a lot of situations.

基本上，`natsort `支持对常见的版本控制模式进行排序，包括我们之前描述的标准版本控制模式(`v1.6`高于`v1.5`)。下面的代码使用库对两个版本进行排序，并验证最低版本是较低的版本:

```
from natsort import natsorted

def check_version(min_version, version):
    versions = natsorted([min_version, version])
    # Return the lower is the minimum version
    return versions[0] == min_version
```

有了这个脚本，我们现在可以启动服务，它将检查思想后端是否有正确的版本。如果您按照*技术要求*部分所述启动服务，您将看到前端启动不正常，并产生`CrashLoopBackOff`状态，如下所示:

```
$ kubectl get pods -n example
NAME READY STATUS RESTARTS AGE
frontend-54fdfd565b-gcgtt 0/1 CrashLoopBackOff 1 12s
frontend-7489cccfcc-v2cz7 0/1 CrashLoopBackOff 3 72s
grafana-546f55d48c-wgwt5 1/1 Running 2 80s
prometheus-6dd4d5c74f-g9d47 1/1 Running 2 81s
syslog-76fcd6bdcc-zrx65 2/2 Running 4 80s
thoughts-backend-6dc47f5cd8-2xxdp 2/2 Running 0 80s
users-backend-7c64564765-dkfww 2/2 Running 0 81s
```

使用`kubectl logs`命令检查一个前端吊舱的日志，查看原因，如下所示:

```
$ kubectl logs frontend-54fdfd565b-kzn99 -n example
Checking minimum version for thoughts_backend
Minimum v1.6, found v1.5
Version v1.5 is incorrect (min v1.6)
```

要解决这个问题，您需要构建一个具有更高版本的思想后端版本，或者降低依赖性要求。这是留在本章末尾的评估。

# 摘要

在本章中，我们学习了如何处理同时与几个微服务一起工作的元素。

首先，我们讨论了当新功能需要更改多个微服务时要遵循的策略，包括如何以有序的方式部署小增量，以及在出现灾难性问题时能够回滚。

然后，我们讨论了定义一个清晰的版本化模式，并向 RESTful 接口添加一个版本端点，该端点允许自我发现微服务的版本。这种自我发现可用于确保依赖于另一个微服务的微服务在依赖关系不存在时不会被部署，这有助于协调发布。

The code in GitHub for the Frontend in this chapter ([https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter11/microservices/frontend](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter11/microservices/frontend)) includes a dependency to the Thoughts Backend that will stop deploying it. Note that the code, as is, won't work. Fixing it is left as an exercise.

我们还学习了如何使用 ConfigMap 来描述在 Kubernetes 集群中不同服务之间共享的配置信息。我们随后描述了如何使用 Kubernetes 秘密来处理敏感且需要额外小心的配置。

在下一章中，我们将看到以高效的方式协调不同团队使用不同微服务的各种技术。

# 问题

1.  在微服务架构系统和单块中发布变更有什么区别？
2.  为什么发布的变更在微服务架构中应该很小？
3.  语义版本化是如何工作的？
4.  在微服务架构系统中，与内部接口的语义版本化相关的问题是什么？
5.  添加版本端点有什么好处？
6.  我们如何解决本章代码中的依赖问题？
7.  我们应该将哪些配置变量存储在共享配置映射中？
8.  您能描述一下在单个共享配置映射中获取所有配置变量的优缺点吗？
9.  Kubernetes 配置图和 Kubernetes 秘密有什么区别？
10.  我们如何改变库本内特的秘密？
11.  想象一下，根据配置，我们决定将`public_key.pub`文件从机密更改为配置映射。我们必须实施哪些变革？

# 进一步阅读

为了在 AWS 上处理你的秘密，你可以和一个叫做 credsstash([https://github.com/fugue/credstash](https://github.com/fugue/credstash))的工具进行交互。你可以在 *AWS SysOps 烹饪书-第二版*([https://www . packtpub . com/cloud-networking/AWS-administration-烹饪书-第二版](https://www.packtpub.com/cloud-networking/aws-administration-cookbook-second-edition))中了解更多如何使用它。*