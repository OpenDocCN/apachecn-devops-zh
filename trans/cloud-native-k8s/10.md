# *第十章*:库本内斯故障排除

本章回顾了有效排除 Kubernetes 集群和运行于其上的应用程序故障的最佳实践方法。这包括讨论常见的 Kubernetes 问题，以及如何分别调试主程序和工作程序。常见的 Kubernetes 问题将以案例研究的形式进行讨论和教学，分为集群问题和应用问题。

我们将首先讨论一些常见的 Kubernetes 故障模式，然后再讨论如何最好地排除集群和应用程序的故障。

在本章中，我们将涵盖以下主题:

*   了解分布式应用程序的故障模式
*   Kubernetes 集群故障排除
*   Kubernetes 上应用程序的故障排除

# 技术要求

为了运行本章中详细介绍的命令，您将需要一台支持`kubectl`命令行工具的计算机以及一个工作正常的 Kubernetes 集群。参见 [*第一章*](01.html#_idTextAnchor016)*与库本内特斯*通讯，了解几种快速与库本内特斯一起起床跑步的方法，以及如何安装`kubectl`工具的说明。

本章使用的代码可以在本书的 GitHub 资源库中找到[https://GitHub . com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/chapter 10](https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter10)。

# 了解分布式应用的故障模式

默认情况下，如果 Kubernetes 组件(以及运行在 Kubernetes 上的应用程序)运行多个副本，则它们是分布式的。这可能会导致一些有趣的故障模式，很难调试。

由于这个原因，如果 Kubernetes 上的应用程序是无状态的，它们就不太容易出现故障——在这种情况下，状态被卸载到运行在 Kubernetes 之外的缓存或数据库中。像 StatefulSets 和 PersistentVolumes 这样的 Kubernetes 原语可以让在 Kubernetes 上运行有状态的应用程序变得更加容易，而且随着每个版本的发布，在 Kubernetes 上运行有状态的应用程序的体验都在提高。尽管如此，决定在 Kubernetes 上运行完全有状态的应用程序会带来复杂性，并因此带来失败的可能性。

分布式应用程序中的失败可能由许多不同的因素引起。像网络可靠性和带宽限制这样简单的事情可能会导致重大问题。这些差异如此之大，以至于*太阳微系统公司*的彼得·多伊奇(Peter Deutsch)帮助解决了分布式计算的*谬误*(以及*詹姆斯·高斯林*，后者增加了第 8 点)，这是分布式应用程序中常见的失败因素。在论文*分布式计算的谬误解释*、 *Arnon Rotem-Gal-Oz* 中讨论了这些谬误的来源([https://www.rgoarchitects.com/Files/fallacies.pdf](https://www.rgoarchitects.com/Files/fallacies.pdf))。

谬误如下，按数字顺序排列:

1.  网络是可靠的。
2.  延迟为零。
3.  带宽是无限的。
4.  网络是安全的。
5.  拓扑不会改变。
6.  有一个管理员。
7.  运输成本为零。
8.  网络是同质的。

Kubernetes 是在考虑到这些谬误的情况下设计和开发的，因此更加宽容。它还有助于解决运行在 Kubernetes 上的应用程序的这些问题，但并不完美。因此，当您的应用程序在 Kubernetes 上进行容器化和运行时，很有可能会在遇到这些问题时出现问题。每一个谬误，当被假设为不真实的，并得出其逻辑结论时，都会在分布式应用程序中引入失败模式。让我们回顾一下适用于 Kubernetes 和运行在 Kubernetes 上的应用程序的每个谬误。

## 网络可靠

运行在多个逻辑机器上的应用程序必须通过互联网进行通信——因此网络中的任何可靠性问题都可能引发问题。具体而言，在 Kubernetes 上，控制平面本身可以分布在高可用性设置中(这意味着具有多个主节点的设置–参见 [*第 1 章*](01.html#_idTextAnchor016) 、*与 Kubernetes 通信*)，这意味着可以在控制器级别引入故障模式。如果网络不可靠，那么 kubelets 可能无法与控制平面通信，从而导致 Pod 放置问题。

类似地，控制平面的节点可能无法相互通信，尽管`etcd`当然是用能够容忍通信故障的一致协议构建的。

最后，工作节点可能无法相互通信，在微服务场景中，这可能会导致问题，具体取决于 Pod 的放置。在某些情况下，工作人员可能都能够与控制平面通信，但仍然无法相互通信，这可能会导致 Kubernetes 覆盖网络出现问题。

与一般的不可靠性一样，延迟也会导致许多相同的问题。

## 延迟为零

如果网络延迟很大，许多与网络不可靠相同的故障也会出现。例如，kubelets 和控制平面之间的调用可能会失败，导致`etcd`出现不准确的时间段，因为控制平面可能无法联系 kube lets–或正确更新`etcd`。类似地，在工作节点上运行的应用程序之间的请求可能会丢失，否则，如果这些应用程序并置在同一个节点上，这些应用程序将可以正常工作。

## 带宽无限

带宽限制可能会暴露与前两个谬误类似的问题。Kubernetes 目前没有完全支持的方法来基于带宽订阅放置 Pods。这意味着达到网络带宽限制的节点仍然可以为其安排新的 Pods，从而导致请求的故障率和延迟问题增加。有人要求将此添加为核心 Kubernetes 调度功能(基本上是一种调度节点带宽消耗的方式，与 CPU 和内存一样)，但目前，解决方案大多局限于**容器网络接口** ( **CNI** )插件。

重要说明

例如，CNI 带宽插件支持 Pod 级别的流量整形——参见[https://kubernetes . io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/# support-流量整形](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/#support-traffic-shaping)。

第三方 Kubernetes 网络实现也可能提供带宽方面的附加功能，并且许多都与 CNI 带宽插件兼容。

## 网络安全

网络安全的影响远远超出了 Kubernetes 的范围，因为任何不安全的网络都会受到一系列攻击。攻击者可能能够获得对 Kubernetes 群集中主节点或工作节点的 SSH 访问权限，这可能会导致重大违规。由于 Kubernetes 的大部分魔法都发生在网络上，而不是在一台机器上，因此在受到攻击的情况下，访问网络就成了双重问题。

## 拓扑不变

这个谬论在 Kubernetes 的上下文中特别相关，因为不仅元网络拓扑会随着新节点的添加和移除而改变，覆盖网络拓扑也会被 Kubernetes 控制平面和 CNI 直接改变。

因此，某个时刻在一个逻辑位置运行的应用程序可能会在网络中完全不同的位置运行。因此，使用 Pod IPs 来识别逻辑应用程序是一个坏主意——这是服务抽象的目的之一(参见 [*第 5 章*](05.html#_idTextAnchor127)*服务和入口*–*与外部世界通信*)。任何不采用集群内无限拓扑结构(至少涉及入侵防御)的应用程序都可能有问题。例如，将应用程序路由到一个特定的 Pod IP 只会在该 Pod 发生意外时起作用。如果该 Pod 关闭，控制它的部署(例如)将启动一个新的 Pod 来替换它，但 IP 将完全不同。集群域名系统(以及扩展的服务)提供了一种更好的方法来在集群中的应用程序之间发出请求，除非您的应用程序能够根据集群变化(如 Pod 放置)动态调整。

## 管理员只有一个

多个管理员和冲突的规则会导致基础网络出现问题，多个 Kubernetes 管理员通过更改资源配置(如 Pod 资源限制)会导致进一步的问题，从而导致非预期的行为。使用 Kubernetes **基于角色的访问控制** ( **RBAC** )功能可以通过仅给予 Kubernetes 用户所需的权限(例如只读)来帮助解决这个问题。

## 运输成本为零

这种谬误有两种常见的解释方式。首先，传输的延迟成本为零——这显然是不真实的，因为有线数据传输的速度不是无限的，更低级别的网络问题会增加延迟。这基本上与*延迟为零*谬论产生的效果相同。

其次，这种说法可以解释为，为了运输的目的，创建和运营一个网络的成本是零——零美元零美分。虽然这显然是不真实的(只要看看您的云提供商的数据传输费用就能证明这一点)，但这并不特别对应于 Kubernetes 上的应用程序故障排除，因此我们将重点关注第一种解释。

## 网络是同质的

最后一个谬误与 Kubernetes 的组件关系不大，更多的是与运行在 Kubernetes 上的应用程序有关。然而，事实是，在当今环境中运行的开发人员非常清楚，应用程序联网可能在不同的应用程序中有不同的实现——从 HTTP 1 和 2 到 *gRPC* 等协议。

现在，我们已经回顾了 Kubernetes 上应用程序失败的一些主要原因，我们可以深入到对 Kubernetes 和运行在 Kubernetes 上的应用程序进行故障排除的实际过程中。

# 库本内特集群故障排除

由于 Kubernetes 是一个分布式系统，它被设计来容忍应用程序运行时的故障，大多数(但不是全部)问题都集中在控制平面和应用编程接口上。在大多数情况下，一个工作节点发生故障只会导致 Pods 被重新安排到另一个节点，尽管复合因素会带来问题。

为了浏览常见的 Kubernetes 集群问题场景，我们将使用案例研究方法。这将为您提供调查实际集群问题所需的所有工具。我们的第一个案例研究集中在 API 服务器本身的故障上。

重要说明

出于本教程的目的，我们将假设一个自我管理的集群。EKS、AKS 和 GKE 等托管 Kubernetes 服务通常会移除一些故障域(例如，通过自动缩放和管理主节点)。一个好的规则是首先检查您的托管服务文档，因为任何问题都可能是特定于实现的。

## 案例研究–库伯内斯豆荚放置失败

让我们开始吧。您的集群已经启动并运行，但是您遇到了 Pod 调度问题。豆荚无限期地停留在`Pending`状态。让我们用以下命令来确认这一点:

```
kubectl get pods
```

该命令的输出如下:

```
NAME                              READY     STATUS    RESTARTS   AGE
app-1-pod-2821252345-tj8ks        0/1       Pending   0          2d
app-1-pod-2821252345-9fj2k        0/1       Pending   0          2d
app-1-pod-2821252345-06hdj        0/1       Pending   0          2d
```

如我们所见，我们的吊舱没有一个在运行。此外，我们正在运行该应用程序的三个副本，但没有一个得到安排。下一步是检查节点状态，看看是否有任何问题。运行以下命令获取输出:

```
kubectl get nodes
```

我们得到以下输出:

```
  NAME           STATUS     ROLES    AGE    VERSION
  node-01        NotReady   <none>   5m     v1.15.6
```

这个输出为我们提供了一些有用的信息——我们只有一个工作节点，它不可用于调度。当`get`命令没有给我们足够的信息通过时，`describe`通常是一个很好的下一步。

让我们运行`kubectl describe node node-01`并检查`conditions`键。为了将所有内容整齐地放在页面上，我们删除了一个栏，但最重要的栏在那里:

![Figure 10.1 – Describe Node Conditions output](Images/B14790_10_001.jpg)

图 10.1–描述节点条件输出

我们这里有一个有趣的分裂:两个`MemoryPressure`和`DiskPressure`都很好，而`OutOfDisk`和`Ready`的条件是未知的，带有消息`kubelet stopped posting node status`。乍看之下，这似乎很荒谬——当 kubelet 停止工作时，`MemoryPressure`和`DiskPressure`怎么会没事呢？

重要部分在`LastTransitionTime`栏。kubelet 最近的内存和磁盘专用通信发送了肯定的状态。然后，在稍后的时间，库布雷停止发布其节点状态，导致`OutOfDisk`和`Ready`条件的`Unknown`状态。

在这一点上，我们确信我们的节点是问题所在 kubelet 不再向控制平面发送节点状态。然而，我们不知道为什么会出现这种情况。这可能是网络错误、机器本身的问题或更具体的问题。我们需要进一步挖掘才能弄清楚。

这里一个很好的下一步是更接近我们的故障节点，因为我们可以合理地假设它遇到了某种问题。如果你可以访问`node-01`虚拟机或机器，现在是 SSH 进入的好时机。一旦我们进入机器，让我们开始进一步排除故障。

首先，让我们检查节点是否可以通过网络访问控制平面。如果没有，这就是 kubelet 不能发布状态的明显原因。让我们假设一个场景，其中我们的集群控制平面(例如内部负载平衡器)在`10.231.0.1`可用。为了检查我们的节点是否可以访问 Kubernetes API 服务器，我们可以如下 ping 控制平面:

```
ping 10.231.0.1   
```

重要说明

为了找到控制平面 IP 或 DNS，请检查您的集群配置。在托管的 Kubernetes 服务中，如 AWS 弹性 Kubernetes 服务或 Azure AKS，这可能可以在控制台中查看。例如，如果您使用 kubeadm 引导自己的集群，这是您在安装过程中提供的一个值。

让我们检查结果:

```
Reply from 10.231.0.1: bytes=1500 time=28ms TTL=54
Reply from 10.231.0.1: bytes=1500 time=26ms TTL=54
Reply from 10.231.0.1: bytes=1500 time=27ms TTL=54
```

这证实了这一点——我们的节点确实可以与库本内特斯的控制平面对话。所以，网络不是问题。接下来，让我们检查实际的 kubelet 服务。节点本身似乎是可操作的，网络也很好，所以从逻辑上讲，kubelet 是下一个要检查的东西。

Kubernetes 组件在 Linux 节点上作为系统服务运行。

重要说明

在 Windows Nodes 上，故障排除说明会略有不同–有关更多信息，请参见 Kubernetes 文档([https://Kubernetes . io/docs/setup/production-environment/Windows/intro-Windows-in-Kubernetes/](https://kubernetes.io/docs/setup/production-environment/windows/intro-windows-in-kubernetes/))。

为了找出我们的`kubelet`服务的状态，我们可以运行以下命令:

```
systemctl status kubelet -l 
```

这为我们提供了以下输出:

```
 • kubelet.service - kubelet: The Kubernetes Node Agent
   Loaded: loaded (/lib/systemd/system/kubelet.service; enabled)
  Drop-In: /etc/systemd/system/kubelet.service.d
           └─10-kubeadm.conf
   Active: activating (auto-restart) (Result: exit-code) since Fri 2020-05-22 05:44:25 UTC; 3s ago
     Docs: http://kubernetes.io/docs/
  Process: 32315 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_SYSTEM_PODS_ARGS $KUBELET_NETWORK_ARGS $KUBELET_DNS_ARGS $KUBELET_AUTHZ_ARGS $KUBELET_CADVISOR_ARGS $KUBELET_CERTIFICATE_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=1/FAILURE)
 Main PID: 32315 (code=exited, status=1/FAILURE)
```

看起来我们的 kubelet 当前没有运行，它因失败而退出。这解释了我们所看到的关于集群状态和 Pod 问题的一切。

要真正解决问题，我们可以首先尝试使用命令重启`kubelet`:

```
systemctl start kubelet
```

现在，让我们用状态命令重新检查我们的`kubelet`的状态:

```
 • kubelet.service - kubelet: The Kubernetes Node Agent
   Loaded: loaded (/lib/systemd/system/kubelet.service; enabled)
  Drop-In: /etc/systemd/system/kubelet.service.d
           └─10-kubeadm.conf
   Active: activating (auto-restart) (Result: exit-code) since Fri 2020-05-22 06:13:48 UTC; 10s ago
     Docs: http://kubernetes.io/docs/
  Process: 32007 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_SYSTEM_PODS_ARGS $KUBELET_NETWORK_ARGS $KUBELET_DNS_ARGS $KUBELET_AUTHZ_ARGS $KUBELET_CADVISOR_ARGS $KUBELET_CERTIFICATE_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=1/FAILURE)
 Main PID: 32007 (code=exited, status=1/FAILURE)
```

看来`kubelet` 又失败了。我们需要获得一些关于故障模式的额外信息，以便找出发生了什么。

让我们使用`journalctl`命令找出是否有相关的日志:

```
sudo journalctl -u kubelet.service | grep "failed"
```

输出应该向我们显示发生故障的`kubelet`服务的日志:

```
May 22 04:19:16 nixos kubelet[1391]: F0522 04:19:16.83719    1287 server.go:262] failed to run Kubelet: Running with swap on is not supported, please disable swap! or set --fail-swap-on flag to false. /proc/swaps contained: [Filename                                Type                Size        Used        Priority /dev/sda1                               partition        6198732        0        -1]
```

看起来我们已经找到原因了——默认情况下，Kubernetes 不支持在`swap`设置为`on`的 Linux 机器上运行。我们在这里唯一的选择是要么禁用`swap`要么在`--fail-swap-on`标志设置为`false`的情况下重新启动`kubelet`。

在我们的例子中，我们将使用以下命令更改`swap`设置:

```
sudo swapoff -a
```

现在，重新启动`kubelet`服务:

```
sudo systemctl restart kubelet
```

最后，我们来看看我们的修复是否有效。使用以下命令检查节点:

```
kubectl get nodes 
```

这将显示类似于以下内容的输出:

```
  NAME           STATUS     ROLES    AGE    VERSION
  node-01        Ready      <none>   54m    v1.15.6
```

我们的节点终于发布了`Ready`状态！

让我们使用以下命令检查我们的 Pod:

```
kubectl get pods
```

这应该会显示如下输出:

```
NAME                              READY     STATUS    RESTARTS   AGE
app-1-pod-2821252345-tj8ks        1/1       Running   0          1m
app-1-pod-2821252345-9fj2k        1/1       Running   0          1m
app-1-pod-2821252345-06hdj        1/1       Running   0          1m
```

成功！我们的集群是健康的，我们的 Pods 正在运行。

接下来，让我们看看一旦解决了任何集群问题，如何对 Kubernetes 上的应用程序进行故障排除。

# 对 Kubernetes 上的应用程序进行故障排除

一个完美运行的 Kubernetes 集群可能仍然有应用程序问题需要调试。这可能是由于应用程序本身的错误，或者是由于组成应用程序的 Kubernetes 资源的错误配置。与群集故障排除一样，我们将通过案例研究深入探讨这些概念。

## 案例研究 1–服务没有响应

我们将把这一部分分解为 Kubernetes 堆栈不同级别的故障排除，从更高级别的组件开始，然后以深入的 Pod 和容器调试结束。

让我们假设我们已经配置了我们的应用程序`app-1`通过端口`32688`上的`NodePort`服务来响应请求。应用程序监听端口`80`。

我们可以尝试通过一个节点上的`curl`请求来访问我们的应用程序。该命令将如下所示:

```
curl http://10.213.2.1:32688
```

如果失败，`curl`命令的输出如下所示:

```
curl: (7) Failed to connect to 10.231.2.1 port 32688: Connection refused
```

此时，我们的`NodePort`服务没有将请求路由到任何 Pod。按照我们的典型调试路径，让我们首先使用以下命令来查看集群中正在运行哪些资源:

```
kubectl get services
```

添加`-o`宽标志查看更多信息。接下来，运行以下命令:

```
kubectl get services -o wide 
```

这为我们提供了以下输出:

```
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR 
app-1-svc NodePort 10.101.212.57 <none> 80:32688/TCP 3m01s app=app-1
```

很明显，我们的服务有一个合适的节点端口，但是我们的请求没有被路由到 Pods，这从失败的`curl`命令中可以明显看出。

要查看我们的服务设置了哪些路由，让我们使用`get endpoints`命令。这将列出为服务配置的 Pod IPs(如果有):

```
kubectl get endpoints app-1-svc
```

让我们检查命令的结果输出:

```
NAME        ENDPOINTS
app-1-svc   <none>
```

嗯，这里肯定有问题。

我们的服务没有指向任何 Pods。这可能意味着没有任何 Pods 匹配我们的服务选择器可用。这可能是因为根本没有可用的 Pods，或者因为这些 Pods 与服务选择器不匹配。

要检查我们的服务选择器，让我们进入调试路径的下一步，并使用`describe`命令，如下所示:

```
kubectl describe service app-1-svc  
```

这给了我们一个如下所示的输出:

```
Name:                   app-1-svc
Namespace:              default
Labels:                 app=app-11
Annotations:            <none>
Selector:               app=app-11
Type:                   NodePort
IP:                     10.57.0.15
Port:                   <unset> 80/TCP
TargetPort:             80/TCP
NodePort:               <unset> 32688/TCP
Endpoints:              <none>
Session Affinity:       None
Events:                 <none>
```

如您所见，我们的服务被配置为与应用程序上的正确端口通信。然而，选择器正在寻找与标签`app = app-11`匹配的豆荚。因为我们知道我们的应用程序被命名为`app-1`，这可能是我们问题的原因。

让我们编辑我们的服务以寻找正确的 Pod 标签，`app-1`，运行另一个`describe`命令以确保:

```
kubectl describe service app-1-svc
```

这给出了以下输出:

```
Name:                   app-1-svc
Namespace:              default
Labels:                 app=app-1
Annotations:            <none>
Selector:               app=app-1
Type:                   NodePort
IP:                     10.57.0.15
Port:                   <unset> 80/TCP
TargetPort:             80/TCP
NodePort:               <unset> 32688/TCP
Endpoints:              <none>
Session Affinity:       None
Events:                 <none>
```

现在，您可以在输出中看到，我们的服务正在寻找合适的 Pod 选择器，但是我们仍然没有任何端点。让我们通过使用以下命令来检查一下我们的 Pods 发生了什么:

```
kubectl get pods
```

这显示了以下输出:

```
NAME                              READY     STATUS    RESTARTS   AGE
app-1-pod-2821252345-tj8ks        0/1       Pending   0          -
app-1-pod-2821252345-9fj2k        0/1       Pending   0          -
app-1-pod-2821252345-06hdj        0/1       Pending   0          -
```

我们的吊舱仍在等待安排。这解释了为什么即使有适当的选择器，我们的服务也不能正常工作。要了解为什么我们的 Pods 没有被调度，让我们使用`describe`命令:

```
kubectl describe pod app-1-pod-2821252345-tj8ks
```

以下是输出。让我们关注`Events`部分:

![Figure 10.2 – Describe Pod Events output](Images/B14790_10_002.jpg)

图 10.2–描述 Pod 事件输出

从`Events`部分来看，由于容器映像拉取失败，我们的 Pod 似乎无法如期完成。这可能有许多原因——例如，我们的集群可能没有必要的身份验证机制来从私有存储库中提取数据——但这将呈现不同的错误消息。

从上下文和`Events`输出中，我们可以大概假设问题是我们的 Pod 定义正在寻找一个名为`myappimage:lates`的容器，而不是`myappimage:latest`。

让我们用正确的映像名称更新我们的部署规范，并推出更新。

使用以下命令获得确认:

```
kubectl get pods
```

输出如下所示:

```
NAME                              READY     STATUS    RESTARTS   AGE
app-1-pod-2821252345-152sf        1/1       Running   0          1m
app-1-pod-2821252345-9gg9s        1/1       Running   0          1m
app-1-pod-2821252345-pfo92        1/1       Running   0          1m
```

我们的 Pods 现在正在运行，让我们检查一下我们的服务是否注册了正确的端点。使用以下命令来完成此操作:

```
kubectl describe services app-1-svc
```

输出应该是这样的:

```
Name:                   app-1-svc
Namespace:              default
Labels:                 app=app-1
Annotations:            <none>
Selector:               app=app-1
Type:                   NodePort
IP:                     10.57.0.15
Port:                   <unset> 80/TCP
TargetPort:             80/TCP
NodePort:               <unset> 32688/TCP
Endpoints:              10.214.1.3:80,10.214.2.3:80,10.214.4.2:80
Session Affinity:       None
Events:                 <none>
```

成功！我们的服务正确地指向我们的应用程序盒。

在下一个案例研究中，我们将通过对一个启动参数不正确的 Pod 进行故障排除来进行更深入的研究。

## 案例研究 2–吊舱启动命令不正确

假设我们已经正确配置了服务，并且我们的 Pods 正在运行并通过了运行状况检查。然而，我们的 Pod 没有像我们预期的那样响应请求。我们确信这不是 Kubernetes 的问题，而是应用程序或配置的问题。

我们的应用程序容器的工作原理如下:它接受一个带有标志`color`的启动命令，并根据容器的`image`标签将其与一个变量`version number`相结合，然后将其返回给请求者。我们期待我们的申请返回`green 3`。

谢天谢地，Kubernetes 给了我们一些调试应用程序的好工具，我们可以用它们来深入研究我们的特定容器。

首先，让我们`curl`应用程序看看我们得到什么响应:

```
curl http://10.231.2.1:32688  
red 2
```

我们期望`green 3`但是得到了`red 2`，所以看起来输入有问题，版本号变量。先说前者。

像往常一样，我们从使用以下命令检查我们的 Pods 开始:

```
kubectl get pods
```

输出应该如下所示:

```
NAME                              READY     STATUS    RESTARTS   AGE
app-1-pod-2821252345-152sf        1/1       Running   0          5m
app-1-pod-2821252345-9gg9s        1/1       Running   0          5m
app-1-pod-2821252345-pfo92        1/1       Running   0          5m
```

在这个输出中，一切看起来都很好。我们的应用程序似乎是作为部署(因此也是复制集)的一部分运行的——我们可以通过运行以下命令来确保这一点:

```
kubectl get deployments
```

输出应该如下所示:

```
NAME          DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
app-1-pod     3         3         3            3           5m
```

让我们更仔细地看看我们的部署，看看我们的 Pods 是如何使用以下命令进行配置的:

```
kubectl describe deployment app-1-pod -o yaml
```

输出如下所示:

部署中断输出

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-1-pod
spec:
  selector:
    matchLabels:
      app: app-1
  replicas: 3
  template:
    metadata:
      labels:
        app: app-1
    spec:
      containers:
      - name: app-1
        image: mycustomrepository/app-1:2
        command: [ "start", "-color", "red" ]
        ports:
        - containerPort: 80
```

让我们看看我们是否能解决我们的问题，这真的很简单。我们使用了错误版本的应用程序，并且我们的启动命令是错误的。在这种情况下，让我们假设我们的部署规范中没有文件，所以让我们就地编辑它。

让我们使用`kubectl edit deployment app-1-pod`，并将 Pod 规范编辑为以下内容:

固定部署输出

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-1-pod
spec:
  selector:
    matchLabels:
      app: app-1
  replicas: 3
  template:
    metadata:
      labels:
        app: app-1
    spec:
      containers:
      - name: app-1
        image: mycustomrepository/app-1:3
        command: [ "start", "-color", "green" ]
        ports:
        - containerPort: 80
```

保存部署后，您应该开始看到新的 Pods 出现。让我们通过使用以下命令进行双重检查:

```
 kubectl get pods
```

输出应该如下所示:

```
NAME                              READY     STATUS    RESTARTS   AGE
app-1-pod-2821252345-f928a        1/1       Running   0          1m
app-1-pod-2821252345-jjsa8        1/1       Running   0          1m
app-1-pod-2821252345-92jhd        1/1       Running   0          1m
```

最后，让我们提出一个`curl`请求，检查一切是否正常:

```
curl http://10.231.2.1:32688  
```

该命令的输出如下:

```
green 3
```

成功！

## 案例研究 3–带有日志的 Pod 应用故障

花完上一章 [*第九章*](09.html#_idTextAnchor212)*Kubernetes*上的可观测性，实现我们的应用程序的可观测性，让我们来看一个那些工具真的可以派上用场的案例。出于本案例研究的目的，我们将使用手动`kubectl`命令，但是要知道，通过聚合日志(例如，在我们的 EFK 堆栈实现中)，我们可以使调试该应用程序的过程变得更加容易。

在本案例研究中，我们再次部署了 Pods–为了检查它，让我们运行以下命令:

```
kubectl get pods
```

该命令的输出如下:

```
NAME              READY     STATUS    RESTARTS   AGE
app-2-ss-0        1/1       Running   0          10m
app-2-ss-1       1/1       Running   0          10m
app-2-ss-2       1/1       Running   0          10m
```

看起来，在这种情况下，我们使用的是状态集，而不是部署集——这里的一个关键特征是从 0 开始递增的 Pod 标识。

我们可以通过使用以下命令检查状态集来确认这一点:

```
kubectl get statefulset
```

该命令的输出如下:

```
NAME          DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
app-2-ss      3         3         3            3           10m
```

让我们用`kubectl get statefulset -o yaml app-2-ss`来仔细看看我们的状态集。通过使用`get`命令和`-o yaml`命令，我们可以获得与典型的库本内特资源 YAML 相同格式的`describe`输出。

前面命令的输出如下。我们删除了 Pod 规范部分，以保持其较短:

statefulset-output.yaml

```
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: app-2-ss
spec:
  selector:
    matchLabels:
      app: app-2
  replicas: 3
  template:
    metadata:
      labels:
        app: app-2
```

我们知道我们的应用程序正在使用一项服务。让我们看看是哪一个！

运行`kubectl get services -o wide`。输出应该如下所示:

```
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR 
app-2-svc NodePort 10.100.213.13 <none> 80:32714/TCP 3m01s app=app-2
```

很明显我们的服务叫做`app-2-svc`。让我们使用以下命令来查看我们的确切服务定义:

```
kubectl describe services app-2-svc 
```

输出如下:

```
Name:                   app-2-svc
Namespace:              default
Labels:                 app=app-2
Annotations:            <none>
Selector:               app=app-2
Type:                   NodePort
IP:                     10.57.0.12
Port:                   <unset> 80/TCP
TargetPort:             80/TCP
NodePort:               <unset> 32714/TCP
Endpoints:              10.214.1.1:80,10.214.2.3:80,10.214.4.4:80
Session Affinity:       None
Events:                 <none>
```

要查看我们的应用程序为给定输入返回了什么，我们可以在我们的`NodePort`服务上使用`curl`:

```
> curl http://10.231.2.1:32714?equation=1plus1
3
```

基于我们对应用程序的现有了解，我们假设这个调用应该返回`2`，而不是`3`。我们团队中的应用程序开发人员要求我们调查任何日志输出，以帮助他们找出问题所在。

从前面的章节中我们知道，您可以使用`kubectl logs <pod name>`来调查日志输出。在我们的例子中，我们有三个应用程序的副本，所以我们可能无法在这个命令的一次迭代中找到我们的日志。让我们随机挑选一个 Pod，看看它是否符合我们的要求:

```
> kubectl logs app-2-ss-1
>
```

看起来这不是服务于我们请求的 Pod，因为我们的应用程序开发人员告诉我们，当向服务器发出`GET`请求时，应用程序肯定会登录到`stdout`。

我们可以使用一个联合命令从所有三个吊舱中获取日志，而不是单独检查其他两个吊舱。命令如下:

```
> kubectl logs statefulset/app-2-ss
```

输出如下:

```
> Input = 1plus1
> Operator = plus
> First Number = 1
> Second Number = 2
```

这就成功了——而且，我们可以看到对我们问题的一些深刻见解。

除了日志线读数`Second Number`之外，一切都如我们所料。我们的请求显然使用了`1plus1`作为查询字符串，这将使第一个数字和第二个数字(由运算符值分割)等于一。

这将需要一些额外的挖掘。我们可以通过发送额外的请求和检查输出来分类这个问题，以便猜测发生了什么，但是在这种情况下，让 bash 访问 Pod 并弄清楚发生了什么可能会更好。

首先，让我们检查一下我们的 Pod 规范，该规范是从之前的 YAML 状态集中删除的。要查看完整的状态集规范，请查看 GitHub 存储库:

Statefulset-output.yaml

```
spec:
  containers:
  - name: app-2
    image: mycustomrepository/app-2:latest
    volumeMounts:
    - name: scratch
      mountPath: /scratch
  - name: sidecar
    image: mycustomrepository/tracing-sidecar
  volumes:
  - name: scratch-volume
    emptyDir: {}
```

看起来我们的 Pod 正在挂载一个空卷作为暂存盘。它还在每个 Pod 中有两个容器——一个用于应用程序跟踪的边车，以及我们的应用程序本身。我们需要使用`kubectl exec`命令将这些信息`ssh`输入到其中一个吊舱中(本练习中哪个并不重要)。

我们可以使用以下命令来完成:

```
kubectl exec -it app-2-ss-1 app2 -- sh.  
```

这个命令应该给你一个 bash 终端作为输出:

```
> kubectl exec -it app-2-ss-1 app2 -- sh
# 
```

现在，使用我们刚刚创建的终端，我们应该能够研究我们的应用程序代码。出于本教程的目的，我们使用了一个高度简化的 Node.js 应用程序。

让我们检查一下 Pod 文件系统，看看我们正在使用以下命令处理什么:

```
# ls
# app.js calculate.js scratch
```

看起来我们有两个 JavaScript 文件，以及我们之前提到的`scratch`文件夹。假设`app.js`包含引导和服务应用程序的逻辑，`calculate.js`包含进行计算的控制器代码，这可能是一个很好的假设。

我们可以通过打印`calculate.js`文件的内容来确认:

break-calculate . js

```
# cat calculate.js
export const calculate(first, second, operator)
{
  second++;
  if(operator === "plus")
  {
   return first + second;
  }
}
```

即使对 JavaScript 知之甚少或一无所知，这里的问题也非常明显。在执行计算之前，代码正在递增`second`变量。

因为我们在 Pod 的里面，并且我们使用的是非编译语言，我们实际上可以内联编辑这个文件！让我们使用`vi`(或任何文本编辑器)来纠正这个文件:

```
# vi calculate.js
```

并将文件编辑为如下内容:

fixed-calculate.js

```
export const calculate(first, second, operator)
{
  if(operator === "plus")
  {
   return first + second;
  }
}
```

现在，我们的代码应该正常运行。重要的是要声明这个修复只是暂时的。一旦我们的 Pod 关闭或被另一个 Pod 替换，它将恢复到最初包含在容器映像中的代码。然而，这种模式确实允许我们尝试快速修复。

使用`exit` bash 命令退出`exec`会话后，让我们再次尝试我们的网址:

```
> curl http://10.231.2.1:32714?equation=1plus1
2
```

如您所见，我们的 hotfixed 容器显示了正确的结果！现在，我们可以用更持久的方式更新我们的代码和 Docker 映像。使用`exec`是排除和调试运行容器的好方法。

# 总结

在本章中，我们了解了如何在 Kubernetes 上对应用程序进行故障排除。首先，我们介绍了分布式应用程序的一些常见故障模式。然后，我们学习了如何用 Kubernetes 组件来分类问题。最后，我们回顾了执行 Kubernetes 配置和应用程序调试的几个场景。您在本章中学习的 Kubernetes 调试和故障排除技术将在您可能使用的任何 Kubernetes 集群和应用程序中帮助您解决问题。

在下一章 [*第 11 章*](11.html#_idTextAnchor251)*库本内斯上的模板代码生成和 CI/CD*中，我们将研究一些生态系统扩展，用于模板化库本内斯资源清单以及与库本内斯的持续集成/持续部署。

# 问题

1.  分布式系统谬论“*拓扑不变*”如何适用于 Kubernetes 上的应用？
2.  Kubernetes 控制平面组件(和 kubelet)是如何在操作系统级实现的？
3.  你将如何着手调试 Pods 陷入`Pending`状态的问题？你的第一步是什么？你的第二个呢？

# 进一步阅读

*   流量整形的 CNI 插件:https://kubernetes . io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/# support-流量整形