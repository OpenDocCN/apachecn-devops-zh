# 八、编排容器

在前面的章节中，我们为容器联网的需求、如何在 Docker 容器内运行服务以及如何通过开放网络端口和其他先决条件向外部世界公开该服务奠定了坚实的基础。然而，最近出现了一些先进的机制，一些第三方编排平台进入市场，明智地在分布式和不同功能的容器之间建立动态和决定性的联系，以便为全面而紧凑地包含以流程为中心、多层和企业级的分布式应用构建强大的容器。在这个极其多样化但又相互联系的世界里，编排的概念不能长期远离其应有的突出地位。这一章专门用来解释容器编排的本质，它的直接作用是挑选离散的容器来系统地组成复杂的容器，这些容器更直接地与变化的业务期望和权宜之计保持一致。

在本章中，我们将详细讨论以下主题:

*   链接容器
*   编排容器
*   使用`docker-compose`工具编排容器

由于任务关键型应用绝大多数是通过松散耦合但高度内聚的组件/服务构建的，这些组件/服务注定要在地理上分布的信息技术基础设施和平台上运行，组合的概念正受到越来越多的关注和吸引。为了维持良好开端的容器化之旅，容器的编排被规定为接下来的即时、自适应和智能信息技术时代最关键和至关重要的要求之一。有一些经过验证且有前途的方法和符合标准的工具可以实现神秘的编排目标。

## Docker 内置服务发现

Docker 平台固有地支持使用嵌入式**域名服务** ( **域名系统**)对连接到任何用户定义网络的容器进行服务发现。自版本`1.10`以来，该功能已被添加到 Docker 中。嵌入式域名系统功能使 Docker 容器能够在用户定义的网络中使用它们的名称或别名发现彼此。换句话说，来自容器的名称解析请求首先被发送到嵌入式 DNS。然后，用户定义的网络为嵌入式域名系统使用一个特殊的`127.0.0.11` IP 地址，该地址也在`/etc/resolv.conf`中列出。

以下示例将有助于更好地理解 Docker 的内置服务发现功能:

1.  让我们首先使用以下命令创建一个用户定义的网桥网络`mybridge`:

```
      $ sudo docker network create mybridge

```

2.  检查新创建的网络，了解子网范围和网关 IP:

```
 $ sudo docker network inspect mybridge
 [
 {
 "Name": "mybridge",
 "Id": "36e5e088543895f6d335eb92299ee8e118cd0610e0d023f7c42e6e603b935e17",
 "Created": 
 "2017-02-12T14:56:48.553408611Z",
 "Scope": "local",
 "Driver": "bridge",
 "EnableIPv6": false,
 "IPAM": {
 "Driver": "default",
 "Options": {},
 "Config": [
 {
 "Subnet": "172.18.0.0/16",
 "Gateway": "172.18.0.1"
 }
 ]
 },
 "Internal": false,
 "Attachable": false,
 "Containers": {},
 "Options": {},
 "Labels": {}
 }
 ]

```

这里，分配给`mybridge`网络的子网是`172.18.0.0/16`，网关是`172.18.0.1`。

3.  现在，让我们通过将其连接到`mybridge`网络来创建一个容器，如下所示:

```
      $ sudo docker container run \
 -itd --net mybridge --name testdns ubuntu  

```

4.  继续列出分配给容器的 IP 地址，如下图所示:

```
 $ sudo docker container inspect --format \
 '{{.NetworkSettings.Networks.mybridge.IPAddress}}' \
 testdns 
 172.18.0.2

```

显然，`testdns`容器被分配了一个`172.18.0.2` IP 地址。`172.18.0.2`的 IP 地址来自`mybridge`网络的子网(即`172.18.0.0/16`)。

5.  获得容器的 IP 地址后，我们使用`docker container exec`子命令查看容器的`/etc/resolv.conf`文件的内容，如下所示:

```
 $ sudo docker container exec testdns \
 cat /etc/resolv.conf 
 nameserver 127.0.0.11
 options ndots:0

```

这里`nameserver`配置为`127.0.0.11`，是嵌入式 DNS 的 IP 地址。

6.  作为最后一步，让我们使用`busybox`映像 ping`testdns`容器。我们在这里选择了`busybox`映像，因为`ubuntu`映像发货时没有`ping`命令:

```
 $ sudo docker container run --rm --net mybridge \ 
 busybox ping -c 2 testdns
 PING testdns (172.18.0.2): 56 data bytes
 64 bytes from 172.18.0.2: seq=0 ttl=64 
 time=0.085 ms
 64 bytes from 172.18.0.2: seq=1 ttl=64 
 time=0.133 ms

 --- testdns ping statistics ---
 2 packets transmitted, 2 packets received, 
 0% packet loss
 round-trip min/avg/max = 0.085/0.109/0.133 ms

```

太棒了，不是吗！Docker 背后的人已经把它变得如此简单，以至于我们不费力就能在同一个网络中发现容器。

## 链接容器

在引入用户定义网络的概念之前，容器链接主要用于容器间的发现和通信。也就是说，协作容器可以链接在一起，以提供复杂的业务感知服务。链接的容器具有一种源-接收者关系，其中源容器链接到接收者容器，并且接收者安全地从源容器接收各种信息。但是，源容器对它所链接的收件人一无所知。在安全设置中链接容器的另一个值得注意的特征是，链接的容器可以使用安全隧道进行通信，而无需向外部世界公开用于设置的端口。尽管您会发现许多部署使用容器链接技术，但是它们配置起来既麻烦又耗时。此外，它们容易出错。因此，嵌入式域名系统的新方法比传统的容器链接技术更受青睐。

Docker 引擎在`docker run`子命令中提供了`--link`选项，将源容器链接到接收容器。

`--link`选项的格式如下:

```
--link <container>:<alias>

```

这里，`<container>`是源容器的名称，`<alias>`是接收容器看到的名称。容器的名称在 Docker 主机中必须是唯一的，而别名对于收件人容器是非常特定和本地的，因此，别名在 Docker 主机中不必是唯一的。这为在接收者容器中实现和合并具有固定源别名的功能提供了很大的灵活性。

当两个容器链接在一起时，Docker 引擎会自动将一些环境变量导出到接收容器。这些环境变量有明确定义的命名约定，其中变量总是以别名的大写形式作为前缀。例如，如果`src`是给源容器的别名，那么导出的环境变量将以`SRC_`开始。Docker 导出三类环境变量，如下所示:

*   `NAME`:这是第一类环境变量。这些变量采用`<ALIAS>_NAME`的形式，它们携带接收者容器的层次名称作为它们的值。例如，如果源容器的别名是`src`，而接收容器的名称是`rec`，那么环境变量及其值将是`SRC_NAME=/rec/src`。
*   `ENV`:这是第二类环境变量，用于通过`docker run`子命令的`-e`选项或`Dockerfile`的`ENV`指令导出源容器中配置的环境变量。这种类型的环境变量采用`<ALIAS>_ENV_<VAR_NAME>`的形式。例如，如果源容器的别名是`src`，变量名是`SAMPLE`，那么环境变量就是`SRC_ENV_SAMPLE`。
*   `PORT`:这是最后一类，也是第三类环境变量，用于将源容器的连接细节导出到接收方。Docker 通过`docker run`子命令的`-p`选项或`Dockerfile`的`EXPOSE`指令为源容器公开的每个端口创建一组变量。

这些变量采用`<ALIAS>_PORT_<port>_<protocol>`形式。此表单用于将源的 IP 地址、端口和协议共享为一个 URL。例如，如果源容器的别名是`src`，暴露的端口是`8080`，协议是`tcp`，IP 地址是`172.17.0.2`，那么环境变量及其值将是`SRC_PORT_8080_TCP=tcp://172.17.0.2:8080`。该网址进一步分为以下三个环境变量:

*   `<ALIAS>_PORT_<port>_<protocol>_ADDR`:此表单携带 URL 的 IP 地址部分(例如`SRC_PORT_8080_TCP_ADDR= 172.17.0.2`)
*   `<ALIAS>_PORT_<port>_<protocol>_PORT`:此表单携带 URL 的端口部分(例如`SRC_PORT_8080_TCP_PORT=8080`)
*   `<ALIAS>_PORT_<port>_<protocol>_PROTO`:此表单携带 URL 的协议部分(例如`SRC_PORT_8080_TCP_PROTO=tcp`)

除了前面的环境变量之外，Docker Engine 还导出了该类别中的一个变量，即`<ALIAS>_PORT`形式的变量，其值将是源容器所有公开端口中最低数量的 URL。例如，如果源容器的别名为`src`，暴露的端口号为`7070`、`8080`和`80`，协议为`tcp`，IP 地址为`172.17.0.2`，则环境变量及其值为`SRC_PORT=tcp://172.17.0.2:80`。

Docker 以结构良好的格式导出这些自动生成的环境变量，以便可以通过编程轻松发现它们。因此，对于接收者容器来说，发现关于源容器的信息变得非常容易。此外，Docker 会自动更新源 IP 地址及其别名，作为收件人的`/etc/hosts`文件中的条目。

在本章中，我们将通过一系列实用的例子深入探讨 Docker Engine 为容器链接提供的上述特性。

首先，让我们选择一个简单的容器链接示例。在这里，我们将向您展示如何在两个容器之间建立链接，并将一些基本信息从源容器传输到接收容器，如以下步骤所示:

1.  我们首先启动一个交互式容器，它可以用作链接的源容器，使用以下命令:

```
      $ sudo docker run --rm --name example -it \
 busybox:latest

```

使用`--name`选项将容器命名为`example`。此外，`--rm`选项用于在您离开容器时清理容器。

2.  使用`cat`命令显示源容器的`/etc/hosts`条目:

```
 / # cat /etc/hosts
 172.17.0.3 a02895551686
 127.0.0.1 localhost
 ::1 localhost ip6-localhost ip6-loopback
 fe00::0 ip6-localnet
 ff00::0 ip6-mcastprefix
 ff02::1 ip6-allnodes
 ff02::2 ip6-allrouters

```

这里，`/etc/hosts`文件中的第一个条目是源容器的 IP 地址(`172.17.0.3`)及其主机名(`a02895551686`)。

3.  我们将继续使用`env`命令显示源容器的环境变量:

```
 / # env
 HOSTNAME=a02895551686
 SHLVL=1
 HOME=/root
 TERM=xterm
 PATH=
 /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
 PWD=/

```

4.  我们现在已经启动了源容器。从同一个 Docker 主机的另一个终端，让我们通过使用`docker run`子命令的`--link`选项将其链接到我们的源容器来启动交互式接收者容器，如下所示:

```
      $ sudo docker run --rm --link example:ex \ 
 -it busybox:latest 

```

这里，名为`example`的源容器链接到以`ex`为别名的接收容器。

5.  让我们使用`cat`命令显示收件人容器的`/etc/hosts`文件的内容:

```
 / # cat /etc/hosts
 172.17.0.4 a17e5578b98e
 127.0.0.1 localhost
 ::1 localhost ip6-localhost ip6-loopback
 fe00::0 ip6-localnet
 ff00::0 ip6-mcastprefix
 ff02::1 ip6-allnodes
 ff02::2 ip6-allrouters
 72.17.0.3 ex

```

当然，一如既往，`/etc/hosts`文件中的第一个条目是容器的 IP 地址及其主机名。但是，`/etc/hosts`文件中值得注意的条目是最后一个条目，其中源容器的 IP 地址(`172.17.0.3`)及其别名(`ex`)是自动添加的。

6.  我们将继续使用`env`命令显示接收者容器的环境变量:

```
 / # env
 HOSTNAME=a17e5578b98e
 SHLVL=1
 HOME=/root
 EX_NAME=/berserk_mcclintock/ex
 TERM=xterm
 PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
 PWD=/

```

显然，一个新的`EX_NAME`环境变量被自动添加到`/berserk_mcclintock/ex`中，作为其值。这里`EX`是别名`ex`的大写形式，`berserk_mcclintock`是收件人容器的自动生成名称。

7.  最后一步，使用广泛使用的`ping`命令 ping 源容器两次，并使用别名作为 ping 地址:

```
 / # ping -c 2 ex
 PING ex (172.17.0.3): 56 data bytes
 64 bytes from 172.17.0.3: seq=0 ttl=64 
 time=0.108 ms
 64 bytes from 172.17.0.3: seq=1 ttl=64 
 time=0.079 ms

 --- ex ping statistics ---
 2 packets transmitted, 2 packets received, 
 0% packet loss
 round-trip min/avg/max = 0.079/0.093/0.108 ms

```

显然，源容器的别名`ex`被解析为`172.17.0.3` IP 地址，并且接收者容器能够成功到达源。在安全容器通信的情况下，不允许在容器之间进行 ping 操作。我们将在[第 11 章](11.html)、*保护 Docker 容器*中看到关于保护容器方面的更多细节。

在前面的例子中，我们可以将两个容器链接在一起，并且还可以通过更新接收容器的`/etc/hosts`文件中源容器的 IP 地址来观察容器之间是如何优雅地联网的。

下一个示例是演示容器链接如何将源容器的环境变量导出到接收容器，这些变量是使用`docker run`子命令的`-e`选项或`Dockerfile`的`ENV`指令配置的。为此，我们将使用`ENV`指令创建一个名为`Dockerfile`的文件，构建一个映像，使用该映像启动一个源容器，然后通过将其链接到源容器来启动一个接收容器:

1.  我们从用`ENV`指令编写`Dockerfile`开始，如下所示:

```
      FROM busybox:latest 
      ENV BOOK="Learning Docker"  \
          CHAPTER="Orchestrating Containers" 

```

这里，我们设置了两个环境变量，`BOOK`和`CHAPTER`。

2.  使用前面的`Dockerfile`中的`docker build`子命令继续构建 Docker 映像`envex`:

```
      $ sudo docker build -t envex .

```

3.  现在，让我们使用刚刚构建的`envex`映像启动一个名为`example`的交互式源容器:

```
      $ sudo docker run -it --rm \
 --name example envex

```

4.  在源容器提示符下，通过调用`env`命令显示所有环境变量:

```
 / # env
 HOSTNAME=b53bc036725c
 SHLVL=1
 HOME=/root
 TERM=xterm
 PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
 BOOK=Learning Docker
 CHAPTER=Orchestrating Containers
 PWD=/

```

在前面所有的环境变量中，`BOOK`和`CHAPTER`变量都是用`Dockerfile`的`ENV`指令配置的。

5.  最后一步，为了说明环境变量的`ENV`类别，使用`env`命令启动接收者容器，如下所示:

```
 $ sudo docker run --rm --link example:ex \
 busybox:latest env
 PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
 HOSTNAME=a5e0c07fd643
 TERM=xterm
 EX_NAME=/stoic_hawking/ex
 EX_ENV_BOOK=Learning Docker
 EX_ENV_CHAPTER=Orchestrating Containers
 HOME=/root

```

[https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Env](https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Env)

引人注目的是，在前面的输出中，前缀为`EX_`的变量是容器链接的结果。我们感兴趣的环境变量是`EX_ENV_BOOK`和`EX_ENV_CHAPTER`，它们最初是通过`Dockerfile`设置为`BOOK`和`CHAPTER`，但作为容器链接的效果修改为`EX_ENV_BOOK`和`EX_ENV_CHAPTER`。虽然环境变量名被翻译，但是存储在这些环境变量中的值保持不变。我们已经在前面的例子中讨论了`EX_NAME`变量名。

在前面的例子中，我们体验了 Docker 如何优雅而轻松地将`ENV`类别变量从源容器导出到接收容器。这些环境变量与源和接收方完全分离，因此一个容器中这些环境变量的值的变化不会影响另一个容器。更准确地说，接收方容器接收的值是在源容器启动期间设置的值。在源容器启动后，对这些环境变量的值所做的任何更改对接收容器都没有影响。收件人容器何时启动并不重要，因为这些值是从 JSON 文件中读取的。

在我们链接容器的最后一个示例中，我们将向您展示如何利用 Docker 功能来共享两个容器之间的连接细节。为了共享容器之间的连接细节，Docker 使用了环境变量的`PORT`类别。以下是制作两个容器并在它们之间共享连接细节的步骤:

1.  使用`EXPOSE`指令加工一个`Dockerfile`露出端口`80`和`8080`，如下图所示:

```
      FROM busybox:latest 
      EXPOSE 8080 80 

```

2.  使用我们刚才创建的`Dockerfile`中的`docker build`子命令，通过运行以下命令，继续构建`portex` Docker 映像:

```
      $ sudo docker build -t portex .

```

3.  现在，让我们使用早期构建的`portex`映像启动一个名为`example`的交互式源容器:

```
      $ sudo docker run -it --rm --name example portex

```

4.  现在我们已经启动了源容器，让我们通过将其链接到源容器来继续在另一个终端上创建接收者容器，并调用`env`命令来显示所有环境变量，如下所示:

```
 $ sudo docker run --rm --link example:ex \
 busybox:latest env
 PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
 HOSTNAME=c378bb55e69c
 TERM=xterm
 EX_PORT=tcp://172.17.0.4:80
 EX_PORT_80_TCP=tcp://172.17.0.4:80
 EX_PORT_80_TCP_ADDR=172.17.0.4
 EX_PORT_80_TCP_PORT=80
 EX_PORT_80_TCP_PROTO=tcp
 EX_PORT_8080_TCP=tcp://172.17.0.4:8080
 EX_PORT_8080_TCP_ADDR=172.17.0.4
 EX_PORT_8080_TCP_PORT=8080
 EX_PORT_8080_TCP_PROTO=tcp
 EX_NAME=/prickly_rosalind/ex
 HOME=/root

```

[https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Expose](https://github.com/thedocker/learning-docker/blob/master/chap08/Dockerfile-Expose)

从前面的`env`命令输出中，很明显 Docker 引擎为每个端口导出了一组四个`PORT`类别环境变量，这些变量是使用`Dockerfile`中的`EXPOSE`指令公开的。此外，Docker 还导出了另一个`PORT`类别变量`EX_PORT`。

## 容器的编排

IT 领域中编排的开创性概念已经存在了很长时间。例如，在**服务计算** ( **供应链**)领域，服务编排的理念以前所未有的方式蓬勃发展，以产生和维持高度健壮和弹性的服务。离散的或原子的服务没有任何实质性的用途，除非它们以特定的顺序组合在一起，以导出过程感知的复合服务。由于编排服务在向外部世界表达和展示其可识别/可发现、可互操作、可用和可组合的服务形式的独特能力方面对企业更具战略优势，因此企业对拥有易于搜索的服务存储库(原子和复合)表现出了极大的兴趣。该存储库反过来又支持企业实现大规模数据和流程密集型应用。很明显，服务的多样性对于组织的发展和壮大至关重要。这一越来越强制性的需求通过使用经验证且有希望的编排功能得到了认知上的解决。

现在，随着我们快速趋向于容器化的信息技术环境，应用和数据容器应该智能地组合起来，以实现大量新一代软件服务。

然而，为了生产高度胜任的协调容器，需要精心选择特定目的容器和不可知容器，并以正确的顺序启动，以便创建协调容器。序列可以来自过程(控制和数据)流程图。手动完成这项复杂而令人生畏的活动会引发一系列嘲讽和批评。幸运的是，Docker 空间中有一些编排工具，可以方便地构建、运行和管理多个容器来构建企业级服务。Docker 公司一直负责生产和促进受 Docker 启发的容器的生成和组装，已经推出了标准化和简化的编排工具(命名为`docker-compose`)，以减少开发人员和系统管理员的工作量。

供应链范例的成熟组合技术在这里被复制到激烈的容器化范例中，以便获得容器化最初设想的好处，特别是在构建强大的应用感知容器方面。

**微服务架构** ( **MSA** )是一个架构概念，旨在通过将软件解决方案的功能分解到离散服务池中来分离软件解决方案。这是通过对许多原则应用架构级别来实现的。管理服务协议正慢慢成为设计和构建大规模信息技术和业务系统的一种受支持的方式。它不仅促进了松散耦合和软件模块化，而且有利于敏捷世界的持续集成和部署。对应用的一部分所做的任何更改都要求对整个应用进行大规模更改。这是持续部署方面的一个祸根和障碍。微服务旨在解决这种情况，因此，MSA 需要轻量级机制、小型、可独立部署的服务，并确保可扩展性和可移植性。使用 Docker 支持的容器可以满足这些要求。

微服务是围绕业务能力构建的，可以通过全自动部署机制独立部署。每个微服务都可以在不中断其他微服务的情况下进行部署，容器为服务以及其他值得注意的设施提供了一个理想的部署和执行环境，例如减少部署时间、隔离管理和简单的生命周期。在容器中快速部署新版本的服务很容易。所有这些因素导致了使用 Docker 必须提供的功能的微服务的爆炸式增长。

如前所述，Docker 正被定位为下一代容器化技术，它提供了一种成熟且潜在的可靠机制来以高效且分布式的方式分发应用。好处是，开发人员可以在保持容器整体完整性的同时调整容器中的应用块。这具有更大的影响，因为酝酿中的趋势是，公司正在构建更小的、自定义的和包含的、易于管理的和离散的服务，以包含在标准化和自动化的容器中，而不是分布在单个物理或虚拟服务器上的大型单片应用。简而言之，来自 Docker 的迅猛的容器化技术为接下来的微服务时代带来了福音。

Docker 的建立和持续是为了实现*运行一次并在各处运行*的难以实现的目标。Docker 容器通常在流程级别隔离，可跨 IT 环境移植，并且易于重复。单个物理主机可以承载多个容器，因此，每个 IT 环境通常都塞满了各种 Docker 容器。容器的空前增长为有效的容器管理带来了麻烦。容器的多样性和相关的异构性被用来急剧增加容器的管理复杂性。因此，编排技术和蓬勃发展的编排工具已经成为加速安全水域容器化进程的战略慰藉。

通过谷歌的 Kubernetes 或 Flocker 等项目，编排跨越包含微服务的多个容器的应用已经成为 Docker 世界的一个主要部分。铺面是另一个用于促进 Docker 容器编排的选项。Docker 在这一领域的新产品是一套三个编排服务，旨在涵盖分布式应用从应用开发到部署和维护的动态生命周期的所有方面。Helios 是另一个 Docker 编排平台，用于部署和管理整个车队的容器。最初，`fig`是容器编排最首选的工具。然而，在最近的过去，处于提升 Docker 技术前沿的公司推出了一个先进的容器编排工具(`docker-compose`)，让使用 Docker 容器的开发人员在容器生命周期中更轻松地工作。

Docker 公司已经意识到为下一代、业务关键型和容器化工作负载提供容器编排能力的重要性，因此购买了最初构想并具体化`fig`工具的公司。然后，Docker 公司将该工具适当地重新命名为`docker-compose`，并引入了大量的增强功能，以使该工具更好地适应容器开发人员和操作团队的不同期望。

以下是`docker-compose`的要点，它被定位为一个未来主义和灵活的工具，用于使用 Docker 定义和运行复杂的应用。借助`docker-compose`，您可以在一个文件中定义应用的组件(它们的容器、配置、链接、卷等)，然后，您可以用一个命令启动一切，这个命令会尽一切努力让它启动并运行。

该工具通过提供一组内置工具来完成此时手动执行的许多任务，从而简化了容器管理。在本节中，我们提供了使用`docker-compose`来执行容器编排的所有细节，以便拥有下一代分布式应用流。

### 使用 docker-compose 编排容器

在本节中，我们将讨论广泛使用的容器编排工具`docker-compose`。`docker-compose`工具是一种非常简单的电动工具，已经被构思和具体化，以方便一组 Docker 容器的运行。换句话说，`docker-compose`是一个编排框架，允许您定义和控制多容器服务。它使您能够创建一个快速和独立的开发环境，并在生产中编排多个 Docker 容器。`docker-compose`工具在内部利用 Docker 引擎来提取映像、构建映像、以正确的顺序启动容器，并根据`docker-compose.yml`文件中给出的定义在容器/服务之间建立正确的连接/链接。

### 正在安装 docker 合成

写这本书的时候`docker-compose`的最新版本是 1.11.2，建议你和 Docker 1 . 9 . 1 或以上版本一起使用。您可以在 GitHub 位置([https://github.com/docker/compose/releases/latest](https://github.com/docker/compose/releases/latest))找到最新官方发布的`docker-compose`。

我们已经将`docker-compose`的安装过程自动化，并在[http://sjeeva.github.io/getcompose](http://sjeeva.github.io/getcompose)提供给公众使用。这些自动化脚本准确识别最新版本的`docker-compose`，下载并安装在`/usr/local/bin/docker-compose`:

*   像这样使用`wget`工具:

```
      $ wget -qO- http://sjeeva.github.io/getcompose \
 | sudo sh

```

*   像这样使用`curl`工具:

```
      $ curl -sSL http://sjeeva.github.io/getcompose \
 | sudo sh

```

或者，您可以选择直接从 GitHub 软件仓库安装特定版本的`docker-compose`。在这里可以找到下载安装`docker-compose`版本`1.11.2`的方式方法:

像这样使用`wget`工具:

```
sudo sh -c 'wget -qO- \
 https://github.com/docker/compose/releases/tag/1.11.2/ \
 docker-compose-`uname -s`-`uname -m` > \
 /usr/local/bin/docker-compose; \
 chmod +x /usr/local/bin/docker-compose'

```

像这样使用`curl`工具:

```
curl -L https://github.com/docker/compose/releases/download/1.11.2/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose

```

`docker-compose`工具也有 Python 包，可以使用`pip`安装程序安装，如下图所示:

```
$ sudo pip install -U docker-compose  

```

`pip`

`pip`

`docker-compose`

成功安装`docker-compose`后，现在可以查看`docker-compose`版本:

```
$ docker-compose --version
docker-compose version 1.11.2, build dfed245

```

### docker 构成档案

`docker-compose`工具使用 **YAML** 编排容器，这是**又一种标记语言**称为`docker-compose`文件。YAML 是一种人性化的数据序列化格式。Docker 作为容器支持工具开始了它的旅程，它作为一个生态系统正在突飞猛进地发展，以自动化和加速大多数任务，如容器供应、网络、存储、管理、编排、安全、治理和持久性。因此，`docker-compose`文件格式及其版本被多次修改以跟上 Docker 平台。在写这个版本的时候，`docker-compose`文件的最新版本是版本 3。下表列出了`docker-compose`文件和 Docker 引擎版本兼容性矩阵:

| **Docker 构成文件格式** | **Docker 引擎** | **备注** |
| 3, 3.1 | 1.13.0+ | 为`docker stack deploy`和`docker secrets`提供支持 |
| Two point one | 1.12.0+ | 引入了一些新参数 |
| Two | 1.10.0+ | 引入对命名卷和网络的支持 |
| one | 1.9.0+ | 将在未来的撰写版本中被否决 |

默认情况下，`docker-compose`工具使用名为`docker-compose.yml`或`docker-compose.yaml`的文件来编排容器。可以使用`docker-compose`工具的`-f`选项修改该默认文件。以下是`docker-compose`文件的格式:

```
version: "<version>" 
services: 
  <service>: 
    <key>: <value> 
    <key>: 
       - <value> 
       - <value> 
networks: 
  <network>: 
    <key>: <value> 

volumes: 
  <volume>: 
    <key>: <value> 

```

这里使用的选项如下:

*   `<version>`:这是`docker-compose`文件的版本。参考前面的版本表。
*   `<service>`:这是服务的名称。一个`docker-compose`文件中可以有多个服务定义。服务名后面应该跟一个或多个键。但是，所有服务必须有一个`image`或一个`build`键，后跟任意数量的可选键。除了`image`和`build`键外，其余键可以直接映射到`docker run`子命令中的选项。该值可以是单个值，也可以是多个值。所有`<service>`定义必须归入顶层`services`键。
*   `<network>`:这是服务使用的网络名称。所有`<network>`定义必须归入顶级`networks`键。
*   `<volume>`:这是服务使用的卷的名称。所有`<volume>`定义必须归入顶级`volume`键。

这里，我们列出了`docker-compose`文件版本 3 中支持的几个键。`docker-compose`支持的所有按键参见[https://docs.docker.com/compose/compose-file](https://docs.docker.com/compose/compose-file)。

*   `image`:这是标签或者映像 ID。
*   `build`:这是一个包含`Dockerfile`的目录的路径。
*   `command`:该键覆盖默认命令。
*   `deploy`:这个键有很多子项，用来指定部署配置。这仅在`docker swarm`模式下使用。
*   `depends_on`:用于指定服务之间的依赖关系。可以根据自身条件进一步扩展到连锁服务。
*   `cap_add`:这给容器增加了一个能力。
*   `cap_drop`:这降低了容器的能力。
*   `dns`:这设置自定义 DNS 服务器。
*   `dns_search`:这将设置自定义的 DNS 搜索服务器。
*   `entrypoint`:该键覆盖默认入口点。
*   `env_file`:这个键可以让你通过文件添加环境变量。
*   `environment`:这将添加环境变量，并使用数组或字典。
*   `expose`:此键暴露端口，不发布给主机。
*   `extends`:这扩展了在相同或不同配置文件中定义的另一个服务。
*   `extra_hosts`:这使您能够向容器内的`/etc/hosts`添加额外的主机。
*   `healthcheck`:这允许我们配置服务健康检查。
*   `labels`:这个键可以让你添加元数据到你的容器中。
*   `links`:这个键链接到另一个服务中的容器。强烈建议不要使用链接。
*   `logging`:用于配置服务的日志记录。
*   `network`:用于将服务加入到顶层`networks`键定义的网络中。
*   `pid`:这使得主机和容器之间能够共享 PID 空间。
*   `ports`:该键暴露端口并指定两个`HOST_port:CONTAINER_port`端口。
*   `volumes`:该键挂载路径或命名卷。命名卷需要在顶层`volumes`键中定义。

### Docker-合成命令

`docker-compose`工具通过一些命令提供了复杂的编排功能。在本节中，我们将列出`docker-compose`选项和命令:

```
docker-compose [<options>] <command> [<args>...]  

```

`docker-compose`工具支持以下选项:

*   `-f`、`--file <file>`:这为`docker-compose`指定了一个替代文件(默认为`docker-compose.yml`文件)
*   `-p`、`--project-name <name>`:指定一个备选项目名称(默认为目录名)
*   `--verbose`:这显示了更多的输出
*   `-v`、`--version`:这会打印版本并退出
*   `-H`、`--host <host>`:这是指定要连接的守护进程套接字
*   `-tls`、`--tlscacert`、`--tlskey`和`--skip-hostname-check`:`docker-compose`工具还支持**传输层安全性** ( **TLS** )的这些标志

`docker-compose`工具支持以下命令:

*   `build`:此命令构建或重建服务。
*   `bundle`:这是用来从撰写文件中创建 Docker 包的，这仍然是 Docker 1.13 上的一个实验特性。
*   `config`:这是一个验证和显示合成文件的命令。
*   `create`:这将创建在合成文件中定义的服务。
*   `down`:此命令用于停止和移除容器和网络。
*   `events`:可以用来查看实时的容器生命周期事件。
*   `exec`:这使您能够在运行的容器中运行命令。它主要用于调试目的。
*   `kill`:这个命令杀死正在运行的容器。
*   `logs`:显示容器的输出。
*   `pause`:此命令用于暂停服务。
*   `port`:打印端口绑定的公共端口。
*   `ps`:这里列出了容器。
*   `pull`:该命令从存储库中提取映像。
*   `push`:该命令将映像推送到存储库。
*   `restart`:这是用来重新启动编写文件中定义的服务。
*   `rm`:这将移除停止的容器。
*   `run`:这运行一次性命令。
*   `scale`:这为服务设置了容器的数量。
*   `start`:该命令启动合成文件中定义的服务。
*   `stop`:这将停止服务。
*   `unpause`:此命令用于解包服务。
*   `up`:这将创建并启动容器。
*   `version`:这打印的是 Docker Compose 的版本。

### 一般用法

在本节中，我们将借助一个示例来体验 Docker Compose 框架提供的编排功能的强大功能。为此，我们将构建一个两层的 web 应用，它将通过一个 URL 接收您的输入，并用相关的响应文本进行响应。该应用是使用以下两种服务构建的，如下所述:

*   **Redis** :这是一个键值数据库，用来存储一个键及其关联的值
*   **Node.js** :这是一个 JavaScript 运行时环境，用于实现 web 服务器功能以及应用逻辑

这些服务中的每一项都封装在两个不同的容器中，使用`docker-compose`工具将它们缝合在一起。以下是服务的体系结构表示:

![](img/image_08_001.png)

这里，在这个例子中，我们从实现`example.js`模块开始，一个 Node.js 文件来实现 web 服务器，以及密钥查找功能。此外，我们将在与`example.js`相同的目录下创建`Dockerfile`来打包 Node.js 运行时环境，然后，使用与`example.js`相同目录下的`docker-compose.yml`文件来定义服务编排。

下面是`example.js`文件，它是简单请求/响应 web 应用的 Node.js 实现。为了演示，在这个示例代码中，我们将请求和响应限制为两个`docker-compose`命令(`build`和`kill`)。为了使代码不言自明，我们在代码中添加了注释:

```
// A Simple Request/Response web application 

// Load all required libraries 
var http = require('http'); 
var url = require('url'); 
var redis = require('redis'); 

// Connect to redis server running 
// createClient API is called with 
//  -- 6379, a well-known port to which the 
//           redis server listens to 
//  -- redis, is the name of the service (container) 
//            that runs redis server 
var client = redis.createClient(6379, 'redis'); 

// Set the key value pair in the redis server 

// Here all the keys proceeds with "/", because 
// URL parser always have "/" as its first character 
client.set("/", "Welcome to Docker-Compose helpernEnter the docker-compose command in the URL for helpn", redis.print); 
client.set("/build", "Build or rebuild services", redis.print); 
client.set("/kill", "Kill containers", redis.print); 

var server = http.createServer(function (request, response) { 
  var href = url.parse(request.url, true).href; 
  response.writeHead(200, {"Content-Type": "text/plain"}); 

  // Pull the response (value) string using the URL 
  client.get(href, function (err, reply) { 
    if ( reply == null ) response.write("Command: " + 
    href.slice(1) + " not supportedn"); 
    else response.write(reply + "n"); 
    response.end(); 
  }); 
}); 

console.log("Listening on port 80"); 
server.listen(80); 

```

[https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose](https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose)

以下文本是打包 Node.js 映像的`Dockerfile`、Node.js 的`redis`驱动程序和`example.js`文件的内容，如前所述:

```
############################################### 
# Dockerfile to build a sample web application 
############################################### 

# Base image is node.js 
FROM node:latest 

# Author: Dr. Peter 
MAINTAINER Dr. Peter <peterindia@gmail.com> 

# Install redis driver for node.js 
RUN npm install redis 

# Copy the source code to the Docker image 
ADD example.js /myapp/example.js 

```

[https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose](https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose)

以下文本来自`docker-compose.yml`文件，该文件定义了 Docker Compose 工具编排的服务:

```
version: "3.1" 
services: 
  web: 
    build: . 
    command: node /myapp/example.js 
    depends_on: 
       - redis 
    ports: 
    - 8080:80 
  redis: 
    image: redis:latest 

```

[https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose](https://github.com/thedocker/learning-docker/tree/master/chap08/orchestrate-using-compose)

我们在这个`docker-compose.yml`文件中定义了两个服务，其中这些服务用于以下目的:

*   名为`web`的服务是使用当前目录中的`Dockerfile`构建的。此外，它指示您通过运行以`/myapp/example.js`(网络应用实现)作为参数的`node`(node . js 运行时)来启动容器。由于这个 Node.js 应用使用了`redis`数据库，所以在使用`depends_on`指令的`redis`服务之后，`web`服务被强制启动。此外，`80`容器端口映射到`8080` Docker 主机的端口。
*   名为`redis`的服务被指示启动一个带有`redis:latest`映像的容器。如果映像不在 Docker 主机中，Docker 引擎将从中央存储库或私有存储库中将其取出。

现在，让我们继续我们的示例，使用`docker-compose build`命令构建 Docker 映像，使用`docker-compose up`命令启动容器，并连接浏览器以验证请求/响应功能，如下所述:

1.  必须从存储`docker-compose.yml`文件的目录中执行`docker-compose`命令。此外，`docker-compose`将每个`docker-compose.yml`文件视为一个项目，并采用来自`docker-compose.yml`文件目录的项目名称。当然，这可以使用`-p`选项来覆盖。因此，作为第一步，让我们更改存储`docker-compose.yml`文件的目录:

```
      $ cd ~/example

```

2.  使用`docker-compose build`命令构建服务:

```
      $ sudo docker-compose build

```

3.  使用`docker-compose pull`命令从存储库中提取映像:

```
      $ sudo docker-compose pull

```

4.  使用`docker-compose up`命令继续调出`docker-compose.yml`文件中指示的服务:

```
 $ sudo docker-compose up
 Creating network "example_default" with the default
 driver
 Creating example_redis_1
 Creating example_web_1
 Attaching to example_redis_1, example_web_1
 redis_1 | 1:C 03 Feb 18:09:40.743 # Warning: no 
 config file specified, using the default config. 
 In order to specify a config file use redis-server 
 /path/to/redis.conf 
 . . . TRUNCATED OUTPUT . . .
 redis_1 | 1:M 03 Feb 18:03:47.438 * The server 
 is now ready to accept connections on port 6379
 web_1 | Listening on port 80
 web_1 | Reply: OK
 web_1 | Reply: OK
 web_1 | Reply: OK

```

由于目录名为`example`，`docker-compose`工具假定项目名为`example`。如果你注意输出的第一行，你会注意到`example_default`网络正在创建。默认情况下，Docker Compose 工具会创建此桥接网络，该网络由服务用于 IP 地址解析。因此，这些服务只需使用组合文件中定义的服务名称就可以到达其他服务。

5.  使用`docker-compose`工具成功编排服务后，让我们从不同的终端调用`docker-compose ps`命令，列出与示例`docker-compose`项目相关的容器:

```
 $ sudo docker-compose ps
 Name Command 
 State Ports
 -------------------------------------------------- 
 -------------------------
 example_redis_1 /entrypoint.sh redis-server 
 Up 6379/tcp
 example_web_1 node /myapp/example.js 
 Up 0.0.0.0:8080->80/tcp

```

显然，两个`example_redis_1`和`example_web_1`容器已经启动并运行。容器名称以`example_`为前缀，为`docker-compose`项目名称。

6.  在 Docker 主机的不同终端上探索我们自己的请求/响应 web 应用的功能，如下图所示:

```
 $ curl http://localhost:8080
 Welcome to Docker-Compose helper
 Enter the docker-compose command in the URL for help
 $ curl http://localhost:8080/build
 Build or rebuild services
 $ curl http://localhost:8080/something
 Command: something not supported

```

`web`

`http://localhost:8080`

`web`

`8080`

`8080`

`https://<docker host ip>:8080`

很酷，不是吗？在`docker-compose.yml`文件的帮助下，我们只需很少的努力就能够将两个不同的服务组合在一起，并提供一个复合服务。

## 摘要

这一章被合并到本书中，以便为您提供无缝编排多个容器的所有探索和规定细节。我们广泛讨论了容器编排的需求，以及简化和精简日益复杂的容器编排过程的支持工具。为了证实编排在制作企业级容器时是多么方便和有帮助，并说明编排过程，我们采用了一个简单的例子来解释整个色域，这种方法被广泛采用。我们开发了一个 web 应用，并将其包含在一个标准容器中。同样，我们采用了一个数据库容器，它是前端 web 应用的后端。数据库在另一个容器中执行。我们看到了如何通过 Docker Engine 的容器链接特性，使用不同的技术，让 web 应用容器知道数据库。为此，我们使用了一个开源工具(`docker-compose`)。

在下一章中，我们将讨论 Docker 如何促进软件测试，尤其是集成测试，并给出一些实用的例子。