# 五、Magnum——OpenStack中的COE管理

本章将解释用于管理Magnum的**容器编排引擎** ( **COE** )的 OpenStack 项目。Magnum 是用于管理基础设施和在 OpenStack 之上运行容器的 OpenStack 项目，由不同的技术支持。在本章中，我们将涵盖以下主题:

*   万能游戏攻略
*   概念
*   主要特征
*   成分
*   走过
*   Magnum DevStack 安装
*   管理COE

# 万能游戏攻略

Magnum 是 OpenStack 服务，由 OpenStack 容器团队于 2014 年创建，旨在支持**容器编排引擎** ( **COE** )提供在 OpenStack 中将容器作为一流资源进行部署和管理的能力。

目前，Magnum 支持 Kubernetes、Apache Mesos 和 Docker Swarm COEs。Magnum 使用 Heat 在由 OpenStack 提供的虚拟机或裸机上协调这些 Coe。它使用包含运行容器所需工具的操作系统映像。Magnum 提供 KeyStone 兼容的 API 和完整的多租户解决方案，用于在 OpenStack 集群之上管理您的 COEs。

Magnum 集群是由不同的 OpenStack 服务提供的各种资源的集合。它由 Nova 提供的一组虚拟机、连接中子创建的这些虚拟机的网络、连接到煤渣创建的虚拟机的卷等组成。Magnum集群也可以有一些外部资源，这取决于创建集群时提供的选项。例如，我们可以通过在集群模板中指定`-master-lb-enabled`选项为集群创建一个外部负载平衡器。

Magnum的一些突出特点是:

*   为COE的完整生命周期管理提供标准应用编程接口
*   支持多个 Coe，如 Kubernetes、Swarm、Mesos 和 DC/OS
*   支持向上或向下扩展集群的能力
*   支持容器集群的多租户
*   容器集群部署模型的不同选择:虚拟机或裸机
*   提供基于 KeyStone 的多租户安全和授权管理
*   基于中子的多租户网络控制和隔离
*   支撑煤渣为容器提供容积
*   与 OpenStack 集成
*   安全容器集群访问(**传输层安全性** ( **TLS** )已启用
*   群集还可以使用对外部基础架构的支持，如 DNS、公共网络、公共发现服务、Docker 注册表、负载平衡器等
*   Barbican 提供秘密存储，例如用于集群内 TLS 的证书
*   基于 Kuryr 的容器级隔离网络

# 概念

Magnum有几个不同类型的对象，形成了Magnum系统。在这一节中，我们将详细了解它们，并了解它们在Magnum中的用途。两个重要的对象是集群和集群模板。以下是Magnum物件的清单:

# 集群模板

这之前被称为 **Baymodel** 。集群模板相当于一个 Nova 风味。对象存储关于集群的模板信息，如关键帧、图像等，这用于一致地创建新集群。一些参数与集群的基础设施相关，而另一些参数用于特定的 COE。不同的COE可以有多个集群模板。

A cluster template cannot be updated or deleted if is used by any cluster.

# 串

这以前被称为**海湾**。它是安排工作的节点对象的集合。该节点可以是虚拟机或裸机。Magnum 根据特定集群模板中定义的属性以及集群的一些附加参数来部署集群。Magnum 部署由集群驱动程序提供的编排模板，以创建和配置运行 COE 的所有必要基础设施。创建集群后，用户可以使用每个 COE 的本机 CLIs 在 OpenStack 之上运行他们的应用。

# 集群驱动程序

群集驱动程序包含设置群集所需的所有必要文件。它包含一个热模板，用于定义要为任何集群创建的资源、在集群上安装和配置服务的脚本、驱动程序的版本信息以及模板定义。

# 热堆叠模板

**热栈模板** ( **热**)是一个定义将形成 COE 集群的资源的模板。每种 COE 类型都有不同的模板，具体取决于其安装步骤。该模板由 Magnum 传递给 Heat，以建立一个完整的 COE 集群。

# 模板定义

模板定义表示Magnum属性和热模板属性之间的映射。它也有输出，由Magnum消费。它指示给定集群将使用哪种集群类型。

# 证书

证书是一个代表Magnum集群的证书颁发机构证书的对象。Magnum 生成服务器和客户端证书，同时创建一个集群来提供 Magnum 服务和 COE 服务之间的安全通信。CA 证书和密钥存储在 Magnum 中，供用户安全访问群集时使用。用户需要生成一个客户端证书、一个客户端密钥和一个证书签名请求(CSR)，然后向 Magnum 发送一个请求以获得签名，并下载签名证书以访问集群。

# 服务

服务是存储`magnum-conductor`二进制信息的对象。此对象包含诸如服务运行的主机、服务是否被禁用、最后看到的详细信息等信息。管理员可以使用这些信息来查看`magnum-conductor`服务的状态。

# 统计数据

Magnum 还管理每个项目使用情况的统计数据。这些信息有助于管理。Stats 对象包含关于租户或所有活动租户的任何管理员或用户的当前使用情况的一些指标。它们提供信息，例如集群、节点等的总数。

# 定额

配额是存储任何给定项目的资源配额的对象。对资源施加配额限制了可以消耗的资源数量，这有助于保证*公平性*或创建时资源的公平分配。如果一个特定的项目需要更多的资源，配额的概念提供了按需增加资源数量的能力，前提是不超过系统限制。配额与物理资源紧密相关，并且是可计费的实体。

# 主要特征

我们已经了解到，除了上一节中的 COE 基础设施管理之外，Magnum 还提供了各种功能。在接下来的几节中，我们将讨论Magnum的一些高级功能。

# Kubernetes 的外部负载平衡器

默认情况下，Magnum 使用Flannel为 Kuberenetes 中的资源提供网络连接。Pod 和服务可以使用这个私有容器网络相互访问和访问外部互联网。但是，这些资源不能从外部网络访问。为了允许从外部网络访问，Magnum 提供了为 Kubernetes 集群设置外部负载平衡器的支持。

Please refer to [https://docs.openstack.org/magnum/latest/user/#steps-for-the-cluster-administrator](https://docs.openstack.org/magnum/latest/user/#steps-for-the-cluster-administrator) to set up a Kubernetes load balancer using Magnum.

# 传输层安全性

Magnum 允许我们使用 TLS 在集群的服务和外部世界之间建立安全通信。Magnum的顶级域名系统通信分为三层:

*   Magnum服务和集群应用编程接口端点之间的通信。
*   集群工作节点和主节点之间的通信。
*   终端用户和集群之间的通信。最终用户使用本机客户端库与群集进行交互，并使用证书通过安全网络进行通信。这适用于命令行界面和为特定集群使用客户端的程序。每个客户端都需要有效的证书来进行身份验证并与群集通信。

前两种情况由 Magnum 在内部实现，它创建、存储和配置服务来使用证书进行通信，并且不向用户公开。最后一种情况涉及用户创建证书，签名，然后使用它来访问集群。

Magnum 使用巴比肯存储证书。这为证书的存储提供了另一个安全级别。Magnum 还支持存储证书的其他方式，例如将证书存储在指挥节点的本地文件系统或 Magnum 数据库中。

有关如何配置客户端访问安全集群的更多详细信息，请参考[https://docs . open stack . org/magnum/latest/user/#与安全集群接口](https://docs.openstack.org/magnum/latest/user/#interfacing-with-a-secure-cluster)。

# 缩放比例

缩放是Magnum的另一个强大功能。Magnum支持集群的缩放，而容器的缩放超出了Magnum的范围。扩展集群可以帮助用户在集群中添加或删除节点。在扩展时，Magnum 创建一个虚拟机或裸机，在其上部署 COE 服务，然后将其注册到集群。缩小时，Magnum 会尝试移除工作负载最少的节点。

参见*管理 COEs* 部分，了解如何扩展集群。

# 储存；储备

Magnum支持煤渣为容器提供块存储，可以是持久存储，也可以是短暂存储。

# 短暂存储

对容器文件系统的所有更改都可以存储在本地文件系统或煤渣卷中。这是容器退出后被删除的临时存储。Magnum 提供了额外的煤渣容积，用作带有容器的临时存储。用户可以使用`docker-volume-size`属性在集群模板中指定卷大小。此外，用户可以选择不同的卷类型，如设备映射器，并用`docker_volume_type`属性覆盖它。

# 持久存储

当容器退出时，可能需要保存它的数据。为此，可以安装一个带有煤渣容积的容器。当容器退出时，卷将被卸载，从而保留数据。

有许多第三方卷驱动程序支持煤渣作为后端，例如 Rexray 和 Flocker。Magnum 目前支持 Rexray 作为 Swarm 的卷驱动程序，以及用于 Kubernetes 的 Mesos 和 child。

# 通知

Magnum 生成关于使用数据的通知。这些数据对于第三方应用很有用，可以用于计费、配额管理、监控等目的。为了提供通知的标准格式，Magnum 使用了**云审计数据联盟** ( **CADF** )格式。

# 容器监控

Magnum 还支持对容器的监控。它收集诸如容器 CPU 负载、可用 inode 数量、接收的字节累积计数、内存、节点的 CPU 统计等指标。所提供的监控栈依赖于 COE 环境中存在的以下一组容器和服务:

*   顾问
*   节点导出器
*   普罗米修斯
*   格拉凡娜

用户可以通过在Magnum集群模板的定义中指定给定的两个可配置标签来设置该监控栈，这两个标签是`prometheus_monitoring`当设置为真时，监控将被启用，而`grafana_admin_password`是管理员密码。

# 成分

*Magnum行为*或部分中的图表显示了Magnum的架构，它有两个名为`magnum-api`和`magnum-conductor`的二进制文件组成了Magnum系统。Magnum与热互动，做配器。这意味着 Heat 是 OpenStack 组件，它与 Nova、中子和煤渣等各种其他项目进行对话，为 COE 建立基础设施，然后在其上安装 COE。我们现在将了解服务的详细功能。

# Magnum原料药

Magnum应用编程接口是一个 WSGI 服务器，服务于用户发送给Magnum的应用编程接口请求。Magnum应用编程接口有许多控制器来处理每个资源的请求:

*   海湾模型
*   海湾
*   证书
*   串
*   集群模板
*   Magnum服务公司
*   配额
*   统计数据

Baymodel 和 Bay 将分别被集群和集群模板取代。每个控制器处理对特定资源的请求。他们验证权限请求，验证 OpenStack 资源(例如验证集群模板中传递的图像是否存在于扫视中)，使用输入数据为资源创建数据库对象，并通过 AMQP 服务器将请求传递给`magnum-conductor`。对`magnum-conductor`的调用可以是同步的，也可以是异步的，这取决于每个操作的处理时间。

例如，列表调用可以是同步的，因为它们不耗时，而创建请求可以是异步的。一旦接收到来自指挥服务的响应，`magnum-api`服务将响应返回给用户。

# 万能指挥

Magnum指挥是一个 RPC 服务器，为Magnum提供协调和数据库查询支持。它是无状态和水平可扩展的，这意味着指挥服务的多个实例可以同时运行。`magnum-conductor`服务选择集群驱动，然后将模板文件发送给 Heat 服务进行安装，最后用对象详细信息更新数据库。

这是 Magnum 的架构图，显示了 Magnum 中的不同组件、它们与哪些其他 OpenStack 项目通信，以及为运行任何 COE 而调配的基础架构:

![](img/00020.jpeg)

# 走过

在本节中，我们将向您介绍 Magnum 创建 COE 集群的过程。本节讨论 OpenStack 中各种项目的请求流和组件交互。在 Magnum 中配置集群涉及到 OpenStack 内部多个组件之间的交互。

在 Magnum 中配置集群的请求流程如下:

1.  用户通过命令行界面或地平线向`magnum-api`发送一个 REST 应用编程接口调用，以创建一个集群，身份验证令牌从 KeyStone 接收。
2.  `magnum-api`接收请求，并将令牌和访问权限的验证请求发送给 KeyStone。
3.  KeyStone 验证令牌，并发送带有角色和权限的更新后的身份验证头。
4.  `magnum-api`然后验证请求的配额。如果配额超过硬限制，则会引发异常，抱怨*资源限制已超过*，并且请求以`403` HTTP 状态存在。
5.  然后完成集群模板中指定的所有 OpenStack 资源的验证。例如，`magnum-api`与`nova-api`对话，检查指定的按键是否存在。如果验证失败，请求以`400` HTTP 状态存在。
6.  `magnum-api`如果请求中没有指定名称，则为集群生成一个名称。
7.  `magnum-api`然后为集群创建一个数据库对象。
8.  `magnum-api`向万能指挥发送 RPC 异步调用请求，进一步处理该请求。
9.  `magnum-conductor`从消息队列中挑选请求。
10.  `magnum-conductor`将集群的状态设置为`CREATE_IN_PROGRESS`，并将条目存储在数据库中。
11.  `magnum-conductor`为集群创建受信者、信任和证书，并将它们设置为集群供以后使用。
12.  根据集群模板中提供的集群分布、COE 类型和服务器类型，`magnum-conductor`为集群选择驱动程序。
13.  `magnum-conductor`然后从集群驱动中提取模板文件、模板、环境文件和 heat 参数，然后将请求发送给 Heat 来创建栈。

14.  然后，Heat 与 Nova、中子和煤渣等多个 OpenStack 服务进行对话，以建立集群并在其上安装 COE。
15.  在 Heat 中创建栈后，栈 ID 和集群状态在 Magnum 数据库中设置为`CREATE_COMPLETE`。

There are periodic tasks in Magnum which sync the cluster status in the Magnum database at a specific time interval.

# Magnum DevStack 安装

要安装带有开发栈的 Magnum，请执行以下步骤:

1.  如果需要，为开发栈创建根目录:

```
        $ sudo mkdir -p /opt/stack
        $ sudo chown $USER /opt/stack
        Clone DevStack repo:
        $ git clone https://git.openstack.org/openstack-dev/devstack
        /opt/stack/devstack  
```

2.  我们将以启用Magnum、热和中子所需的最小`local.conf`设置运行开发栈:

```
    $ cat > /opt/stack/devstack/local.conf << END
    [[local|localrc]]
    DATABASE_PASSWORD=password
    RABBIT_PASSWORD=password
    SERVICE_TOKEN=password
    SERVICE_PASSWORD=password
    ADMIN_PASSWORD=password
    # magnum requires the following to be set correctly
    PUBLIC_INTERFACE=eth1

    # Enable barbican service and use it to store TLS certificates
    enable_plugin barbican 
    https://git.openstack.org/openstack/barbican

    enable_plugin heat 
    https://git.openstack.org/openstack/heat

    # Enable magnum plugin after dependent plugins
    enable_plugin magnum 
    https://git.openstack.org/openstack/magnum

    # Optional:  uncomment to enable the Magnum UI plugin in 
    Horizon
    #enable_plugin magnum-ui 
    https://github.com/openstack/magnum-ui

    VOLUME_BACKING_FILE_SIZE=20G
    END

```

Please note that we have to use Barbican here for storing the TLS certificate generated by Magnum. For details, see the *Transport Layer Security* section under the *Key Features* section.

Also, make sure to use the appropriate interface for setup in `local.conf`.

3.  现在，运行 DevStack:

```
        $ cd /opt/stack/devstack
        $ ./stack.sh  
```

4.  你将有一个Magnum设置运行。要验证安装，请检查运行的 Magnum 服务列表:

```
$ magnum service-list
+----+----------+------------------+-------+----------+-----------------+------------------------
-+---------------------------+
| id | host     | binary           | state | disabled | disabled_reason | created_at             
| updated_at                |
+----+----------+------------------+-------+----------+-----------------+------------------------
-+---------------------------+
| 1  | devstack | magnum-conductor | up    | False    | -               | 2017-09
19T11:14:12+00:00 | 2017-09-19T14:06:41+00:00 |
+----+----------+------------------+-------+----------+-----------------+------------------------
-+---------------------------+  
```

# 管理COE

Magnum 在 OpenStack 中为集群的生命周期提供了无缝管理。当前的操作是基本的 CRUD 操作，具有一些高级功能，例如扩展集群、设置外部负载平衡器、使用 TLS 设置安全集群等。在本节中，我们将创建一个 Swarm 集群模板，使用该模板创建一个 Swarm 集群，然后，我们将在集群上运行一些工作负载来验证我们的集群状态。

首先，我们将准备我们的会话，以便能够使用各种 OpenStack 客户端，包括 Magnum、中子和扫视。创建一个新的外壳并获取开发栈`openrc`脚本:

```
$ source /opt/stack/devstack/openrc admin admin  
```

创建一个要与群集模板一起使用的 keypair。该密钥将用于 ssh 到集群节点:

```
$ openstack keypair create --public-key ~/.ssh/id_rsa.pub testkey
+-------------+-------------------------------------------------+
| Field       | Value                                           |
+-------------+-------------------------------------------------+
| fingerprint | d2:8d:c8:d2:2a:82:fc:aa:98:17:5f:9b:22:08:8a:f7 |
| name        | testkey                                         |
| user_id     | 4360ea27027a4d9d97e749bba9698915                |
+-------------+-------------------------------------------------+  
```

DevStack 创建了一个 Fedora 原子微操作系统映像，供 Magnum 使用。用户还可以在扫视中创建其他图像，以便在他们的群集中使用。验证一眼中创建的图像:

```
$ openstack image list
+--------------------------------------+------------------------------------+--------+
| ID                                   | Name                               | Status |
+--------------------------------------+------------------------------------+--------+
| 482bd0b4-883d-4fc5-bf26-a88a98ceddd1 | Fedora-Atomic-26-20170723.0.x86_64 | active |
| 6862d910-a320-499e-a19f-1dbcdc79455f | cirros-0.3.5-x86_64-disk           | active |
+--------------------------------------+------------------------------------+--------+
```

现在，用群体 COE 类型创建一个 Magnum 集群模板。这在本质上类似于新星的味道，并告诉Magnum如何构建集群。集群模板指定了要在我们的集群中使用的所有资源，例如 Fedora Atomic 映像、Nova keypair、网络等:

```
$ magnum cluster-template-create swarm-template --image Fedora-Atomic-26-20170723.0.x86_64 --keypair testkey --external-network public --flavor m1.small --docker-volume-size 5  --dns-nameserver 8.8.8.8 --coe swarm
+-----------------------+--------------------------------------+
| Property              | Value                                |
+-----------------------+--------------------------------------+
| insecure_registry     | -                                    |
| labels                | {}                                   |
| updated_at            | -                                    |
| floating_ip_enabled   | True                                 |
| fixed_subnet          | -                                    |
| master_flavor_id      | -                                    | 
| uuid                  | 0963601a-50aa-4361-9f6f-5f64f0826da8 |
| no_proxy              | -                                    |
| https_proxy           | -                                    |
| tls_disabled          | False                                |
| keypair_id            | testkey                              |
| public                | False                                |
| http_proxy            | -                                    |
| docker_volume_size    | 5                                    |
| server_type           | vm                                   |
| external_network_id   | public                               |
| cluster_distro        | fedora-atomic                        |
| image_id              | Fedora-Atomic-26-20170723.0.x86_64   |
| volume_driver         | -                                    |
| registry_enabled      | False                                |
| docker_storage_driver | devicemapper                         |
| apiserver_port        | -                                    |
| name                  | swarm-template                       |
| created_at            | 2017-09-19T13:06:28+00:00            |
| network_driver        | docker                               |
| fixed_network         | -                                    |
| coe                   | swarm                                |
| flavor_id             | m1.small                             |
| master_lb_enabled     | False                                |
| dns_nameserver        | 8.8.8.8                              |
+-----------------------+--------------------------------------+  
```

使用以下命令验证集群模板的创建:

```
$ magnum cluster-template-list
+--------------------------------------+----------------+
| uuid                                 | name           |
+--------------------------------------+----------------+
| 0963601a-50aa-4361-9f6f-5f64f0826da8 | swarm-template |
+--------------------------------------+----------------+  
```

使用前面的模板创建集群。该集群将创建一组虚拟机，并在其上安装 Docker Swarm:

```
$ magnum cluster-create swarm --cluster-template swarm-template --node-count 1
Request to create cluster f42f5dfc-a2d0-4f89-9af1-566c666727c3 has been accepted.  
```

集群的初始状态为`CREATE_IN_PROGRESS`。梦龙在完成集群创建后将状态更新为`CREATE_COMPLETE`。

Heat 可用于查看栈或特定集群状态的详细信息。

要检查所有集群栈的列表，请使用以下命令:

```
$ openstack stack list
+--------------------------------------+--------------------+----------------------------------+-------------------+----------------------+--------------+
| ID                                   | Stack Name         | Project                          | Stack Status       | Creation Time        | Updated Time |
+--------------------------------------+--------------------+----------------------------------+--------------------+----------------------+--------------+
| 9d39e877-32ff-4904-a349-727274caee68 | swarm-5g5ilw3lak6p | 8c4a19b957904085992dd800621459b6 | CREATE_IN_PROGRESS | 2017-09-19T13:07:52Z | None         |
+--------------------------------------+--------------------+----------------------------------+--------------------+----------------------+--------------+  
```

要查看集群的详细信息，请执行以下操作:

```
$ magnum cluster-show swarm
+---------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Property            | Value                                                                                                                                                                                                                                                                                                                                                                                                |
+---------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| labels              | {}                                                                                                                                                                                                                                                                                                                                                                                                   |
| updated_at          | 2017-09-19T13:16:41+00:00                                                                                                                                                                                                                                                                                                                                                                            |
| keypair             | testkey                                                                                                                                                                                                                                                                                                                                                                                              |
| node_count          | 1                                                                                                                                                                                                                                                                                                                                                                                                    |
| uuid                | f42f5dfc-a2d0-4f89-9af1-566c666727c3                                                                                                                                                                                                                                                                                                                                                                 |
| api_address         | https://172.24.4.4:6443
|
| master_addresses    | ['172.24.4.2']                                                                                                                                                                                                                                                                                                                                                                                       |
| create_timeout      | 60                                                                                                                                                                                                                                                                                                                                                                                                   |
| status              | CREATE_COMPLETE                                                                                                                                                                                                                                                                                                                                                                                        |
| docker_volume_size  | 5                                                                                                                                                                                                                                                                                                                                                                                                    |
| master_count        | 1                                                                                                                                                                                                                                                                                                                                                                                                    |
| node_addresses      | ['172.24.4.3']                                                                                                                                                                                                                                                                                                                                                                                                   |
| status_reason       | Stack CREATE completed successfully                                                                                                                                                                                                                                           |
| coe_version         | 1.2.5                                                                                                                                                                                                                                                                                                                                                                                                |
| cluster_template_id | 0963601a-50aa-4361-9f6f-5f64f0826da8                                                                                                                                                                                                                                                                                                                                                                 |
| name                | swarm                                                                                                                                                                                                                                                                                                                                                                                                |
| stack_id            | 9d39e877-32ff-4904-a349-727274caee68                                                                                                                                                                                                                                                                                                                                                                 |
| created_at          | 2017-09-19T13:07:46+00:00                                                                                                                                                                                                                                                                                                                                                                            |
| discovery_url       | https://discovery.etcd.io/af18b93f0d1b64db0d803a1c76e4d0d0                                                                                                                                                                                                                                                                                                                                           |
| container_version   | 1.12.6                                                                                                                                                                                                                                                                                                                                                                                               |
+---------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+  
```

我们现在需要设置 Docker CLI 来使用我们用适当的凭据创建的集群集群。

创建一个`dir`来存储`certs`和`cd`。Docker 使用了`DOCKER_CERT_PATH` env 变量，它期望`ca.pem`、`key.pem`和`cert.pem`在该目录中:

```
$ export DOCKER_CERT_PATH=~/.docker
$ mkdir -p ${DOCKER_CERT_PATH}
$ cd ${DOCKER_CERT_PATH}
```

生成一个 RSA 密钥:

```
$ openssl genrsa -out key.pem 4096
```

创建`openssl`配置以帮助生成企业社会责任:

```
$ cat > client.conf << END
[req]
distinguished_name = req_distinguished_name
req_extensions     = req_ext
prompt = no
[req_distinguished_name]
CN = Your Name
[req_ext]
extendedKeyUsage = clientAuth
END 
```

运行`openssl req`命令生成企业社会责任:

```
$ openssl req -new -days 365 -config client.conf -key key.pem -out client.csr    
```

现在您已经有了您的客户端 CSR，使用 Magnum CLI 对其进行签名并下载签名证书:

```
$ magnum ca-sign --cluster swarm-cluster --csr client.csr > cert.pem
$ magnum ca-show --cluster swarm-cluster > ca.pem  
```

将命令行界面设置为使用顶级域名。这个`env var`被 Docker 消耗掉了:

```
$ export DOCKER_TLS_VERIFY="1" 
```

设置要使用的正确主机，这是 Swarm API 服务器端点的公共 IP 地址。

这个`env var`被 Docker 消耗掉了:

```
$ export DOCKER_HOST=$(magnum cluster-show swarm-cluster | awk '/
api_address /{print substr($4,7)}')  
```

接下来，我们将在这个 Swarm 集群中创建一个容器。该容器将 ping 地址`8.8.8.8`四次:

```
$ docker run --rm -it cirros:latest ping -c 4 8.8.8.8  
```

您应该会看到类似如下的输出:

```
PING 8.8.8.8 (8.8.8.8): 56 data bytes
64 bytes from 8.8.8.8: seq=0 ttl=40 time=25.513 ms
64 bytes from 8.8.8.8: seq=1 ttl=40 time=25.348 ms
64 bytes from 8.8.8.8: seq=2 ttl=40 time=25.226 ms
64 bytes from 8.8.8.8: seq=3 ttl=40 time=25.275 ms

--- 8.8.8.8 ping statistics ---
4 packets transmitted, 4 packets received, 0% packet loss
round-trip min/avg/max = 25.226/25.340/25.513 ms  
```

创建集群后，您可以通过更新`node_count`属性来动态地向集群添加节点或从集群中移除节点。例如，要再添加一个节点，请执行以下操作:

```
$ magnum cluster-update swarm replace node_count=2  
```

更新过程继续时，集群的状态将为`UPDATE_IN_PROGRESS`。更新完成后，状态将更新为`UPDATE_COMPLETE`。减少`node_count`会删除节点上所有已删除的现有容器。Magnum 尝试删除工作量最少的节点。

# 摘要

在本章中，我们详细了解了 OpenStack 容器基础设施管理服务 Magnum。我们研究了Magnum不同的物体。然后，我们了解了 Magnum 的组件和架构。然后，我们在 Magnum 中提供了用户请求工作流的详细概述。

最后，我们看了如何使用 DevStack 为 Magnum 安装开发设置，然后使用 Magnum CLI 做了一个动手练习，创建了一个 Docker Swarm COE。

在下一章中，我们将了解 Zun，这是一个面向 OpenStack 的容器管理服务。