# 5.AKS 中常见故障的处理

Kubernetes 是一个具有许多工作部件的分布式系统。AKS 为你抽象了其中的大部分，但当坏事情发生时，你仍然有责任知道该往哪里看，如何应对。许多故障处理是由 Kubernetes 自动完成的；但是，您会遇到需要手动干预的情况。

在部署在 AKS 之上的应用程序中，有两个地方可能会出错。要么集群本身有问题，要么部署在集群顶部的应用程序有问题。本章特别关注集群问题。集群可能会出现几个问题。

首先可能出错的是群集中的一个节点可能变得不可用。这可能是由于 Azure 基础架构中断或虚拟机本身的问题(如操作系统崩溃)造成的。无论哪种方式，Kubernetes 都会监控集群中的节点故障，并将自动恢复。在本章中，您将看到这一过程在起作用。

Kubernetes 集群中的第二个常见问题是资源不足故障。这意味着您尝试部署的工作负载需要的资源比集群上可用的资源多。您将学习如何监控这些信号以及如何解决它们。

另一个常见问题是装载存储的问题，当节点变得不可用时就会出现这种问题。当 Kubernetes 中的节点变得不可用时，Kubernetes 不会分离连接到此故障节点的磁盘。这意味着这些磁盘不能被其他节点上的工作负载使用。您将看到这方面的一个实际例子，并学习如何从这次失败中恢复。

我们将在本章深入探讨以下主题:

*   处理节点故障
*   解决资源不足的故障
*   处理存储装载问题

在本章中，您将了解常见的故障场景，以及这些场景的解决方案。首先，我们将介绍节点故障。

#### 注意:

参考库本内特家的艰难之路(https://github.com/kelseyhightower/kubernetes-the-hard-way)，这是一个很好的教程，来了解库本内特家所在的街区。关于 Azure 版本，请参考 Kubernetes the Hard Way-Azure Translation([https://github . com/ivanforavanti/Kubernetes-the Hard Way on Azure](https://github.com/ivanfioravanti/kubernetes-the-hard-way-on-azure))。

## 处理节点故障

有意(为了节省成本)或无意，节点可能会宕机。当这种情况发生时，你不会想听到众所周知的凌晨 3 点的电话，说你的系统出了问题。Kubernetes 可以自动为您处理故障节点上的移动工作负载。在本练习中，您将部署留言簿应用程序，并在集群中关闭一个节点，看看 Kubernetes 会如何响应:

1.  Ensure that your cluster has at least two nodes:

    kubectl 获取节点

    这将产生如图 5.1 所示的输出:

    ![List of nodes in the created cluster](image/B17338_05_01.jpg)

    图 5.1:集群中的节点列表

    如果集群中没有两个节点，请在 Azure 门户中查找集群，导航到节点池，选择要扩展的池，然后单击扩展。然后您可以将节点计数缩放到 2 个节点，如图 5.2*所示:*

    ![Scaling the cluster size to two nodes using the Azure portal](image/B17338_05_02.jpg)

    图 5.2:扩展集群

2.  As an example application in this section, deploy the guestbook application. The YAML file to deploy this has been provided in the source code for this chapter (**guestbook-all-in-one.yaml**). To deploy the guestbook application, use the following command:

    kubectl create -f 留言簿一体机. yaml

3.  Watch the **service** object until the public IP becomes available. To do this, type the following:

    忽必烈得到服务-w

    #### 注意

    您也可以通过使用**Kubernetes get SVC**而不是完整的**Kubernetes get service**来获得服务。

4.  This will take a couple of seconds to show you the updated external IP. *Figure 5.3* shows the service's public IP. Once you see the public IP appear (20.72.244.113 in this case), you can exit the watch command by hitting *Ctrl* + *C*:

    ![Fetching the external IP of the Service object](image/B17338_05_03.jpg)

    图 5.3:前端服务的外部 IP 从<pending>变为实际的 IP 地址</pending>

5.  Go to **http://<EXTERNAL-IP>** (**http://20.72.244.113** in this case) as shown in *Figure 5.4*:

    ![Browsing to the guestbook application using the external IP](image/B17338_05_04.jpg)

    图 5.4:浏览到留言簿应用程序

6.  Let's see where the pods are currently running using the following command:

    kubectl 的豆荚很宽

    这将产生如图 5.5 所示的输出:

    ![List of pods running on nodes 0 and 2](image/B17338_05_05.jpg)

    图 5.5:吊舱分布在节点 0 和节点 2 之间

    这表明您应该将工作负载分布在节点 0 和节点 2 之间。

    #### 注意

    在*图 5.5* 所示的示例中，工作负载分布在节点 0 和节点 2 之间。您可能会注意到这里缺少节点 1。如果您遵循了*第 4 章“构建可扩展应用程序”*中的示例，那么您的集群应该处于类似的状态。这样做的原因是，当 Azure 移除旧节点并向集群添加新节点时(正如您在*第 4 章“构建可扩展应用程序”*中所做的那样)，它会不断增加节点计数器。

7.  Before introducing the node failures, there are two optional steps you can take to verify whether your application can continue to run. You can run the following command to hit the guestbook front end every 5 seconds and get the HTML. It's recommended to open this in a new Cloud Shell window:

    虽然真实；做

    curl-m 1 http://<external-ip>/；</external-ip>

    睡眠 5；

    完成的

    #### 注意

    前面的命令会一直调用你的应用程序，直到你按下 *Ctrl* + *C* 。有时您可能会收到回复，这是意料之中的，因为 Kubernetes 需要几分钟来重新平衡系统。

    您还可以添加一些留言簿条目，看看当您导致节点关闭时会发生什么。这将显示如图 5.6 所示的输出:

    ![Adding a couple of entries in the guestbook application](image/B17338_05_06.jpg)

    图 5.6:在留言簿上写一些信息

8.  In this example, you are exploring how Kubernetes handles a node failure. To demonstrate this, shut down a node in the cluster. You can shut down either node, although for maximum impact it is recommended you shut down the node from *step 6* that hosted the most pods. In the case of the example shown, node 2 will be shut down.

    要关闭这个节点，在 Azure 搜索栏中查找 **VMSS** ( **虚拟机比例集**，选择你的集群使用的比例集，如图*图 5.7* 。如果您的订阅中有多个比例集，请选择其名称对应于*图 5.5* 所示节点名称的比例集:

    ![Searching for vmss in the azure search bar, and selecting the scale set used by your cluster](image/B17338_05_07.jpg)

    图 5.7:寻找托管集群的规模集

    导航到比例集的窗格后，转到实例视图，选择要关闭的实例，然后点击停止按钮，如图*图 5.8* :

    ![Shutting down the desired node through the Instances pane of the scale set used by your cluster](image/B17338_05_08.jpg)

    图 5.8:关闭节点 2

    这将关闭节点。要了解 Kubernetes 对您的吊舱的反应，您可以通过以下命令观察集群中的吊舱:

    kubectl get pods -o wide -w

    过了一会儿，您应该会注意到额外的输出，显示在健康主机上重新安排了豆荚，如图 5.9 所示:

    ![Pods from the failed node getting rescheduled on healthy nodes](image/B17338_05_09.jpg)

    图 5.9:故障节点的 pods 在正常节点上重新创建

    您在这里看到的是:

    *   由于主机变得不健康，运行在节点 2 上的 Redis 主 pod 被终止。
    *   在主机 0 上创建了一个新的 Redis 主 pod。这经历了挂起、包含创建和运行阶段。

    #### 注意

    在前面的例子中，Kubernetes 在重新安排豆荚之前发现宿主不健康。如果您要执行 **kubectl 获取节点**，您会看到节点 2 处于未就绪状态。Kubernetes 中有一个配置叫做**pod-驱逐-超时**，它定义了系统在一个健康的主机上等待重新调度 pod 的时间。默认值为 5 分钟。

9.  如果您在*步骤 7* 期间在留言簿中记录了许多消息，请浏览回留言簿应用程序的公共 IP。你能看到的是，你所有珍贵的信息都不见了！这显示了在节点故障的情况下，对于任何想要存活的数据，拥有**PersistentVolumeClaims**(**PVCs**)的重要性，而在我们这里的应用程序中，情况并非如此。在本章的最后一节，您将看到一个这样的例子。

在本节中，您学习了 Kubernetes 如何通过在健康节点上重新创建 pods 来自动处理节点故障。在下一节中，您将学习如何诊断和解决资源不足的问题。

## 解决资源不足故障

Kubernetes 集群的另一个常见问题是集群资源不足。当集群没有足够的 CPU 功率或内存来调度额外的吊舱时，吊舱将陷入**挂起**状态。您在*第 4 章【构建可扩展的应用程序】中也看到了这种行为。*

Kubernetes 使用请求来计算某个 pod 需要多少 CPU 功率或内存。留言簿应用程序为所有部署定义了请求。如果您打开文件夹**第 05 章**中的**留言簿一体机. yaml** 文件，您将看到以下关于**重新复制**部署的信息:

63 种:部署

64 元数据:

65 名称:redis-复制

...

83 资源:

84 项请求:

85 个 CPU:200 米

86 内存:100 兆

本节解释了**重新复制**部署的每个吊舱需要**200 米**的中央处理器内核( **200** 毫或 **20%** )和**100 兆字节**(兆字节)的内存。在您的 2 个 CPU 集群中(节点 1 关闭)，将其扩展到 10 个单元会导致可用资源出现问题。让我们看看这个:

#### 注意

在 Kubernetes 中，您可以使用二进制前缀表示法或十进制表示法来指定内存和存储。二进制前缀表示法是用 KiB (kibibyte)表示 1，024 字节，用 MiB (mebibyte)表示 1，024 KiB，用 Gib (gibibyte)表示 1，024 MiB。十进制表示法是用千字节表示 1000 字节，兆字节表示 1000 千字节，千兆字节表示 1000 兆字节。

1.  Let's start by scaling the **redis-replica** deployment to 10 pods:

    kubectl 规模部署/redis-副本-副本=10

2.  This will cause a couple of new pods to be created. We can check our pods using the following:

    忽必烈得到 pods

    这将产生如图 5.10 所示的输出:

    ![The Redis replica pod in a Pending state due to a shortage of resources](image/B17338_05_10.jpg)

    图 5.10:一些吊舱处于挂起状态

    此处突出显示的是处于“待定”状态的一个吊舱。如果群集资源不足，就会出现这种情况。

3.  We can get more information about these pending pods using the following command:

    忽必烈描述 pod redis-replica-

    这将向您展示更多细节。在**描述**命令的底部，您应该会看到类似于*图 5.11* 所示的内容:

    ![Fetching more details about the pending pod using the kubectl describe pod command](image/B17338_05_11.jpg)

    图 5.11: Kubernetes 无法安排这个 pod

    它解释了两件事:

    *   其中一个节点的 CPU 资源不足。
    *   其中一个节点有豆荚不能容忍的污点(node.kubernetes.io/unreachable)。这意味着**未就绪的节点**不能接受豆荚。
4.  We can solve this capacity issue by starting up node 2 as shown in *Figure 5.12*. This can be done in a way similar to the shutdown process:

    ![Starting node 2 again from the Instances pane of the selected VMSS](image/B17338_05_12.jpg)

    图 5.12:再次启动节点 2

5.  It will take a couple of minutes for the other node to become available again in Kubernetes. You can monitor the progress on the pods by executing the following command:

    忽必烈得到 pods -w

    这将在几分钟后向您显示一个输出，类似于图 5.13 :

    ![Monitoring the transition of the pods from the Pending state to the Running state](image/B17338_05_13.jpg)

    图 5.13:pod 从挂起状态移动到包含创建到运行

    在这里，您再次看到容器状态从“挂起”变为“正在创建”，最后变为“正在运行”。

6.  如果您重新执行上一个窗格中的**描述**命令，您将看到类似于*图 5.14* 所示的输出:

![Output showing that the Kubernetes scheduler assigned the redis replica pod to node 2](image/B17338_05_14.jpg)

图 5.14:当该节点再次可用时，挂起的荚被分配给该节点

这表明在节点 2 可用后，Kubernetes 在该节点上调度 pod，然后启动容器。

在本节中，您学习了如何诊断资源不足的错误。您可以通过向群集添加另一个节点来解决该错误。在进入最终故障模式之前，清理留言簿部署。

#### 注意

在*第 4 章，构建可扩展的应用程序*中，介绍了**集群自动缩放器**。群集自动缩放器将监控资源不足错误，并自动向群集添加新节点。

让我们通过运行以下**删除**命令来清理留言簿部署:

kubectl delete -f 留言簿一体机. yaml

现在，关闭之前打开的另一个 Cloud Shell 窗口也是安全的。

到目前为止，您已经了解了如何从 Kubernetes 集群中节点的两种故障模式中恢复。首先，您看到了 Kubernetes 如何处理离线的节点，以及系统如何将 pods 重新调度到工作节点。之后，您看到了 Kubernetes 如何使用请求来管理节点上 pods 的调度，以及当集群资源不足时会发生什么。在下一节中，您将了解 Kubernetes 中的另一种故障模式，即当 Kubernetes 遇到存储装载问题时会发生什么。

## 修复存储安装问题

在本章的前面，您注意到了当 Redis 主节点移动到另一个节点时，留言簿应用程序是如何丢失数据的。这是因为该示例应用程序不使用任何持久存储。在本节中，您将看到一个示例，说明当 Kubernetes 将 pod 移动到另一个节点时，如何使用 PVCs 来防止数据丢失。你会看到一个常见的错误，当 Kubernetes 移动附有 PVC 的豆荚时，你会学到如何解决这个问题。

为此，您将重用上一章中的 WordPress 示例。在开始之前，让我们确保集群处于干净状态:

kubectl get all

这应该只显示一个 Kubernetes 服务，如*图 5.15* :

![Checking the status of the cluster using the kubectl get all command](image/B17338_05_15.jpg)

图 5.15:您现在应该只运行一个 Kubernetes 服务

让我们也确保两个节点都在运行并且就绪:

kubectl 获取节点

这将向我们显示两个节点都处于就绪状态，如图 5.16 所示:

![Checking the status of both nodes using the kubectl get nodes command](image/B17338_05_16.jpg)

图 5.16:集群中应该有两个可用的节点

在前面的示例中，在*处理节点故障*部分，您看到如果 pod 重新启动，存储在 **redis-master** 中的消息会丢失。其原因是 **redis-master** 将所有数据存储在其容器中，每当重新启动时，它都会使用没有数据的干净映像。为了在重启后存活，数据必须存储在外部。Kubernetes 使用 PVCs 来抽象底层存储提供者，以提供这种外部存储。

要开始这个例子，设置 WordPress 安装。

### 开始 WordPress 安装

让我们从安装 WordPress 开始。我们将演示其工作原理，然后验证存储在重新启动后是否仍然存在。

如果在上一章中还没有这样做，请为 Bitnami 添加 Helm 存储库:

helm repo add bitnami https://charts . bitnami . com/bitnami

使用以下命令开始重新安装:

头盔安装 wp bitnami/wordpress

这将需要几分钟来处理。您可以通过执行以下命令来跟踪此安装的状态:

忽必烈得到 pods -w

几分钟后，这将向您显示两个状态为“正在运行”的豆荚，两个豆荚的就绪状态均为 1/1，如图 5.17 所示:

![Using kubectl get pods -w to follow the progress of WordPress installation](image/B17338_05_17.jpg)

图 5.17:几分钟后，所有吊舱都将处于运行状态

您可能会注意到 **wp-wordpress** pod 经历了一个错误状态，然后重新启动。这是因为 **wp-mariadb** 吊舱没有及时准备好， **wp-wordpress** 经历了重启。您将在*第 7 章监控 AKS 集群和应用程序*中了解更多关于就绪性以及这如何影响 pod 重启的信息。

在本节中，您看到了如何安装 WordPress。现在，您将看到如何使用持久卷来避免数据丢失。

### 使用持久卷避免数据丢失

一个**持久卷** ( **PV** )是用 Kubernetes 在集群中存储持久数据的方式。在*第 3 章，AKS* 上的应用部署中更详细地讨论了 PVs。让我们探索一下为 WordPress 部署创建的 PVs:

1.  You can get the PersistentVolumeClaims using the following command:

    立方结构得到 pvc

    这将产生如图 5.18 所示的输出:

    ![Fetching the details of the PersistentVolumeClaims using the kubectl get pvc command](image/B17338_05_18.jpg)

    图 5.18:WordPress 部署创建了两个 PVC

    持久卷声明将导致持久卷的创建。PersistentVolume 是所创建的物理资源的链接，在本例中是一个 Azure 磁盘。以下命令显示了实际创建的 PVs:

    忽必烈得到 pv

    这将向您展示两个持久卷:

    ![Using the kubectl get pv command to check the created PersistentVolumes](image/B17338_05_19.jpg)

    图 5.19:创建了两个物理卷来存储物理卷的数据

    您可以获得有关创建的特定持久卷的更多详细信息。复制其中一个 PVs 的名称，并运行以下命令:

    忽必烈描写 pv

    这将向您显示该卷的详细信息，如*图 5.20* :

    ![Using the kubectl describe pv<pv name> command to get details of specific PersistentVolumes](image/B17338_05_20.jpg)

    图 5.20:其中一个 PVs 的细节

    在这里，您可以看到哪个聚氯乙烯声明了这个卷，以及 Azure 中的磁盘名称是什么。

2.  Verify that your site is working:

    忽必烈得到服务

    这将向我们显示我们的 WordPress 站点的公共 IP，如*图 5.21* 所示:

    ![Obtaining the public IP of our WordPress site](image/B17338_05_21.jpg)

    图 5.21:WordPress 站点的公共 IP

3.  If you remember from *Chapter 3, Application deployment of AKS*, Helm showed you the commands you need to get the admin credentials for our WordPress site. Let's grab those commands and execute them to log on to the site as follows:

    头盔状态 wp

    回应用户名:用户

    echo Password:$(kube CTL get secret-namespace default WP-WordPress-o JSON path = " { . data . WordPress-Password } " | base64-d)

    这将向您显示用户名和密码，如*图 5.22* 所示:

![Using Helm commands to obtain a username and password to login to the WordPress site](image/B17338_05_22.jpg)

图 5.22:获取 WordPress 应用程序的用户名和密码

您可以通过以下地址登录我们的网站: **http:// <外部-ip > /admin** 。使用上一步中的凭据登录此处。然后你可以在你的网站上添加一个帖子。点击【写你的第一篇博文】按钮，然后创建一篇短文，如图*图 5.23* :

![Writing your first blog post on the WordPress website](image/B17338_05_23.jpg)

图 5.23:写你的第一篇博文

现在输入一些文字，点击【发布】按钮，如图*图 5.24* 。文本本身并不重要；您编写此文件是为了验证数据是否确实保存在磁盘上:

![Using the Publish button to publish a post with random text on the WordPress website](image/B17338_05_24.jpg)

图 5.24:发布带有随机文本的帖子

如果你现在在**http://<external-IP>**转到你的网站主页，你会看到你的测试帖子，如图*图 5.25* :

![Using the website’s external IP to navigate to the WordPress website and verify the published post](image/B17338_05_25.jpg)

图 5.25:发布的博文出现在主页上

在本节中，您部署了一个 WordPress 站点，登录到您的 WordPress 站点，并创建了一个帖子。在下一节中，您将验证此帖子是否在节点故障后仍然存在。

### 在聚氯乙烯参与下处理吊舱故障

你将对 PVCs 做的第一个测试是杀死豆荚，并验证数据是否确实存在。为此，让我们做两件事:

1.  **Watch the pods in your application**: To do this, use the current Cloud Shell and execute the following command:

    忽必烈得到 pods -w

2.  **Kill the two pods that have the PVC mounted**: To do this, create a new Cloud Shell window by clicking on the icon shown in *Figure 5.26*:

    ![Opening a new Cloud Shell instance](image/B17338_05_26.jpg)

    图 5.26:打开一个新的云外壳实例

    打开新的云外壳后，执行以下命令:

    kubectl delete pod --all

    在原始的云壳中，跟随您之前执行的**观察**命令。您应该会看到类似于*图 5.27* 所示的输出:

    ![Kubernetes creates new pods to recover from the pod outage caused due to the deletion of pods](image/B17338_05_27.jpg)

    图 5.27:删除豆荚后，Kubernetes 会自动重新创建两个豆荚

    如您所见，两个原始的吊舱进入了终止状态。Kubernetes 很快开始制造新的吊舱，从吊舱故障中恢复过来。豆荚经历了与原始豆荚相似的生命周期，从待定到包含创造再到运行。

3.  如果你去你的网站，你应该看到你的演示文章已经被保存了。这就是 PVC 如何帮助您防止数据丢失，因为它们保存了原本不会保存在 pod 本身中的数据。

在本节中，您已经了解了当在同一个节点上重新创建 pods 时，PVCs 如何提供帮助。在下一节中，您将看到当节点出现故障时如何使用 PVC。

### 处理有聚氯乙烯参与的节点故障

在前面的示例中，您看到了当这些吊舱连接了光伏时，Kubernetes 如何处理吊舱故障。在本例中，您将了解 Kubernetes 如何在连接卷时处理节点故障:

1.  Let's first check which node is hosting your application, using the following command:

    kubectl 的豆荚很宽

    在*图 5.28* 所示的例子中，节点 2 托管的是 MariaDB，节点 0 托管的是 WordPress 站点:

    ![Checking the node that is hosting your application](image/B17338_05_28.jpg)

    图 5.28:检查哪个节点托管 WordPress 站点

2.  Introduce a failure and stop the node that is hosting the WordPress pod using the Azure portal. You can do this in the same way as in the earlier example. First, look for the scale set backing your cluster, as shown in *Figure 5.29*:

    ![Searching for vmss in the azure search bar, and selecting the scale set used by your cluster](image/B17338_05_29.jpg)

    图 5.29:寻找托管集群的规模集

3.  Then shut down the node, by clicking on Instances in the left-hand menu, then selecting the node you need to shut down and clicking the Stop button, as shown in *Figure 5.30*:

    ![Shutting down the desired node through the Instances pane of the scale set used by your cluster](image/B17338_05_30.jpg)

    图 5.30:关闭节点

4.  After this action, once again, watch the pods to see what is happening in the cluster:

    kubectl get pods -o wide -w

    与前面的示例一样，Kubernetes 需要 5 分钟才能开始对故障节点采取措施。你可以在*图 5.31* 中看到这种情况发生:

    ![The status of the pod indicates that it is stuck in a ContainerCreating state](image/B17338_05_31.jpg)

    图 5.31:处于容器创建状态的容器

5.  You are seeing a new issue here. The new pod is stuck in a ContainerCreating state. Let's figure out what is happening here. First, describe that pod:

    kube CTL description pods/WP-WordPress-

    您将获得如图 5.32 所示的输出:

    ![Using the kubectl describe command to understand the issue with the pod stuck in theContainerCreating state](image/B17338_05_32.jpg)

    图 5.32:解释为什么容器处于容器创建状态的输出

    这表明音量有问题。您会看到与该卷相关的两个错误: **FailedAttachVolume** 错误说明该卷已被另一个 pod 使用， **FailedMount** 说明当前 pod 无法挂载该卷。您可以通过手动强制移除卡在**终止**状态的旧吊舱来解决这个问题。

    #### 注意

    停留在**终止**状态的吊舱的行为不是 bug。这是默认的 Kubernetes 行为。Kubernetes 文档声明如下:*“Kubernetes(版本 1.5 或更高版本)不会因为节点不可访问而删除 pods。超时后，在不可到达的节点上运行的吊舱进入终止或未知状态。当用户尝试在不可到达的节点上优雅地删除 pod 时，pod 也可能进入这些状态。”*您可以在[https://kubernetes . io/docs/tasks/run-application/force-delete-state-set-pod/](https://kubernetes.io/docs/tasks/run-application/force-delete-stateful-set-pod/)上了解更多。

6.  To forcefully remove the terminating pod from the cluster, get the full pod name using the following command:

    忽必烈得到 pods

    这将向您显示类似于图 5.33 的输出:

    ![Fetching the name of the pod stuck in the Terminating state](image/B17338_05_33.jpg)

    图 5.33:获取停留在终止状态的容器的名称

7.  Use the pod's name to force the deletion of this pod:

    立方删除 pod wordpress-wp- <pod-id>--force</pod-id>

8.  After the pod has been deleted, it will take a couple of minutes for the other pod to enter a Running state. You can monitor the state of the pod using the following command:

    忽必烈得到 pods -w

    这将返回类似于图 5.34 的输出:

    ![The new WordPress pod returning to a Running state](image/B17338_05_34.jpg)

    图 5.34:新的 WordPress 容器返回到运行状态

9.  As you can see, this brought the new pod to a healthy state. It did take a couple of minutes for the system to pick up the changes and then mount the volume to the new pod. Let's get the details of the pod again using the following command:

    忽必烈描写 pod wp-wordpress-

    这将生成如下输出:

    ![The new pod is now attaching the volume and pulling the container image](image/B17338_05_35.jpg)

    图 5.35:新的 pod 现在正在连接卷并拉出容器图像

10.  This shows you that the new pod successfully got the volume attached and that the container image got pulled. This also made your WordPress website available again, which you can verify by browsing to the public IP. Before continuing to the next chapter, clean up the application using the following command:

    头盔删除 wp

    kubectl 删除 pvc --所有

    kubectl delete pv --all

11.  我们也来启动被关闭的节点:回到 Azure 门户中的比例集窗格，点击左侧菜单中的 Instances，选择需要启动的节点，点击 start 按钮，如图*图 5.36* :

![Using the Instances pane of the selected VMSS to start the node that was shut down](image/B17338_05_36.jpg)

图 5.36:再次启动节点 0

在本节中，您学习了当 PVC 没有安装到新的 pod 时，如何从节点故障中恢复。你所需要做的就是强制删除停留在**终止**状态的吊舱。

## 总结

在本章中，您了解了常见的 Kubernetes 故障模式以及如何从中恢复。本章首先介绍了 Kubernetes 如何自动检测节点故障，以及它将如何启动新的 pods 来恢复工作负载。之后，您扩展了您的工作负载，并且让您的集群耗尽了资源。通过再次启动故障节点向群集添加新资源，您从这种情况中恢复过来。

接下来，您看到了 PVs 如何在 pod 外部存储数据。您删除了集群上的所有 pods，并看到 PV 如何确保您的应用程序中没有数据丢失。在本章的最后一个示例中，您看到了如何在连接 PVs 时从节点故障中恢复。您可以通过强制删除终止 pod 来恢复工作负载。这使您的工作量恢复到健康状态。

本章解释了 Kubernetes 中常见的故障模式。在下一章中，我们将向我们的服务介绍 HTTPS 支持，并介绍使用 Azure Active Directory 的身份验证。